@article{Wang2014,
author = {Wang, Lei and Zhan, Jianfeng and Luo, Chunjie and Zhu, Yuqing and Yang, Qiang and He, Yongqiang and Gao, Wanling and Jia, Zhen and Shi, Yingjie and Zhang, Shujie and Zheng, Chen and Lu, Gang and Zhan, Kent and Li, Xiaona and Qiu, Bizhu},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/benchmarks/06835958.pdf:pdf},
isbn = {9781479930975},
title = {{BigDataBench: a Big Data Benchmark Suite from Internet Services}},
year = {2014}
}
@article{Chen2014,
abstract = {In this paper, we review the background and state-of-the-art of big data. We first introduce the general background of big data and review related technologies, such as could computing, Internet of Things, data centers, and Hadoop.We then focus on the four phases of the value chain of big data, i.e., data generation, data acquisition, data storage, and data analysis. For each phase, we introduce the general background, discuss the technical challenges, and review the latest advances. We finally examine the several representative applications of big data, including enterprise management, Internet of Things, online social networks, medial applications, collective intelligence, and smart grid. These discussions aimto provide a comprehensive overview and big-picture to readers of this exciting area. This survey is concluded with a discussion of open problems and future directions.},
author = {Chen, Min and Mao, Shiwen and Liu, Yunhao},
doi = {10.1007/s11036-013-0489-0},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/benchmarks/art{\%}3A10.1007{\%}2Fs11036-013-0489-0.pdf:pdf},
isbn = {1383-469X},
issn = {1383469X},
journal = {Mobile Networks and Applications},
keywords = {Big data,Big data analysis,Cloud computing,Data center,Hadoop,Internet of things,Smart grid},
number = {2},
pages = {171--209},
pmid = {1511170304},
title = {{Big data: A survey}},
volume = {19},
year = {2014}
}
@article{Pavlo2009,
abstract = {There is currently considerable enthusiasm around the MapReduce (MR) paradigm for large-scale data analysis 17. Although the basic control flow of this framework has existed in parallel SQL database management systems (DBMS) for over 20 years, some have called MR a dramatically new computing model 8, 17. In this paper, we describe and compare both paradigms. Furthermore, we evaluate both kinds of systems in terms of performance and development complexity. To this end, we define a benchmark consisting of a collection of tasks that we have run on an open source version of MR as well as on two parallel DBMSs. For each task, we measure each system's performance for various degrees of parallelism on a cluster of 100 nodes. Our results reveal some interesting trade-offs. Although the process to load data into and tune the execution of parallel DBMSs took much longer than the MR system, the observed performance of these DBMSs was strikingly better. We speculate about the causes of the dramatic performance difference and consider implementation concepts that future systems should take from both kinds of architectures.},
author = {Pavlo, a and Paulson, E and Rasin, a and Abadi, D J and DeWitt, D J and Madden, S and Stonebraker, M},
doi = {10.1145/1559845.1559865},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/benchmarks/p165-pavlo.pdf:pdf},
isbn = {9781605585512},
journal = {Distribution},
keywords = {Database Applications, Use Cases, Database Program},
number = {2},
pages = {165--178},
title = {{A Comparison of Approaches to Large-Scale Data Analysis}},
url = {http://portal.acm.org/citation.cfm?id=1559865},
volume = {12},
year = {2009}
}
@article{Li2015,
abstract = {Spark has been increasingly adopted by industries in recent years for big data analysis by providing a fault tolerant, scalable and easy-to-use in memory abstraction. Moreover, the community has been actively developing a rich ecosystem around Spark, making it even more attractive. However, there is not yet a Spark specify benchmark existing in the literature to guide the development and cluster deployment of Spark to better fit resource demands of user applications. In this paper, we present SparkBench, a Spark specific benchmarking suite, which includes a comprehensive set of applications. SparkBench covers four main categories of applications, including machine learning, graph computation, SQL query and streaming applications. We also characterize the resource consumption, data flow and timing information of each application and evaluate the performance impact of a key configuration parameter to guide the design and optimization of Spark data analytic platform.},
author = {Li, Min and Tan, Jian and Wang, Yandong and Zhang, Li and Salapura, Valentina},
doi = {10.1145/2742854.2747283},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/benchmarks/a53-li.pdf:pdf},
isbn = {9781450333580},
journal = {Proceedings of the 12th ACM International Conference on Computing Frontiers - CF '15},
keywords = {benchmarking,cloud computing,evaluation,in memory data analytics,spark},
pages = {1--8},
title = {{SparkBench}},
url = {http://dl.acm.org/citation.cfm?doid=2742854.2747283{\%}5Cnhttp://dl.acm.org/citation.cfm?doid=2742854.2747283{\%}5Cnhttps://github.com/SparkTC/spark-bench{\%}5Cnhttps://bitbucket.org/lm0926/sparkbench{\%}5Cnhttp://people.cs.vt.edu/{~}butta/docs/tpctc2015-sparkbench.pdf},
year = {2015}
}
@techreport{Wang,
abstract = {In this paper, we present NADSort, a sorting system on top of the distributed computing platform Apache Spark [1]. We report performance results of NADSort for Daytona CloudSort and Indy CloudSort benchmarks. NADSort is able to complete the 100TB Daytona CloudSort in 2983.33 seconds on random non-skewed datasets at an average cost of {\$}144.22 and 3057.67 seconds on skewed datasets at an average cost of {\$}147.82, and complete Indy CloudSort in 2983.33 seconds at an average cost of {\$}144.22.},
author = {Wang, Qian and Gu, Rong and Huang, Yihua and Xin, Reynold and Wu, Wei and Song, Jun and Xia, Junluan},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/benchmarks/NADSort2016.pdf:pdf},
pages = {1--6},
title = {{NADSort}},
url = {http://sortbenchmark.org/NADSort2016.pdf}
}
@techreport{Xin2014,
author = {Xin, Reynold and Deyhim, Parviz and Ghodsi, Ali and Meng, Xiangrui and Zaharia, Matei},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/benchmarks/ApacheSpark2014.pdf:pdf},
keywords = {web},
title = {{GraySort on Apache Spark by Databricks}},
url = {http://sortbenchmark.org/ApacheSpark2014.pdf},
year = {2014}
}
@article{Xin2013,
abstract = {From social networks to targeted advertising, big graphs capture the structure in data and are central to recent advances in machine learning and data mining. Unfortunately, directly applying existing data-parallel tools to graph computation tasks can be cumbersome and inefficient. The need for intuitive, scalable tools for graph computation has lead to the development of new graph-parallel systems (e.g. Pregel, PowerGraph) which are designed to efficiently execute graph algorithms. Unfortunately, these new graph-parallel systems do not address the challenges of graph construction and transformation which are often just as problematic as the subsequent computation. Furthermore, existing graph-parallel systems provide limited fault-tolerance and support for interactive data mining. We introduce GraphX, which combines the advantages of both data-parallel and graph-parallel systems by efficiently expressing graph computation within the Spark data-parallel framework. We leverage new ideas in distributed graph representation to efficiently distribute graphs as tabular data-structures. Similarly, we leverage advances in data-flow systems to exploit in-memory computation and fault-tolerance. We provide powerful new operations to simplify graph construction and transformation. Using these primitives we implement the PowerGraph and Pregel abstractions in less than 20 lines of code. Finally, by exploiting the Scala foundation of Spark, we enable users to interactively load, transform, and compute on massive graphs.},
archivePrefix = {arXiv},
arxivId = {1402.2394},
author = {Xin, Reynold S. and Gonzalez, Joseph E. and Franklin, Michael J. and Stoica, Ion},
doi = {10.1145/2484425.2484427},
eprint = {1402.2394},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/spark/a2-xin.pdf:pdf},
isbn = {9781450321884},
issn = {0002-9513},
journal = {First International Workshop on Graph Data Management Experiences and Systems - GRADES '13},
pages = {1--6},
title = {{GraphX: A Resilient Distributed Graph System on Spark}},
url = {http://dl.acm.org/citation.cfm?doid=2484425.2484427},
year = {2013}
}
@article{Engle2012,
abstract = {Shark is a research data analysis system built on a novel coarse-grained distributed shared-memory abstraction. Shark marries query processing with deep data analysis, providing a unified system for easy data manipulation using SQL and pushing sophisticated analysis closer to data. It scales to thousands of nodes in a fault-tolerant manner. Shark can answer queries 40X faster than Apache Hive and run machine learning programs 25X faster than MapReduce programs in Apache Hadoop on large datasets.},
author = {Engle, Cliff and Lupher, Antonio and Xin, Reynold and Zaharia, Matei and Franklin, Michael J. and Shenker, Scott and Stoica, Ion},
doi = {10.1145/2213836.2213934},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/spark/p689-engle.pdf:pdf},
isbn = {9781450312479},
issn = {1450312470},
journal = {Proc. of the SIGMOD - Intl. Conf. on Management of Data},
keywords = {data warehouse,databases,machine learning,resilient distributed dataset,shark,spark},
pages = {689--692},
title = {{Shark: fast data analysis using coarse-grained distributed memory}},
url = {http://dl.acm.org/citation.cfm?id=2213836.2213934{\%}5Cnhttp://dl.acm.org/citation.cfm?doid=2213836.2213934},
year = {2012}
}
@article{Bose2005,
abstract = {Scientific research relies as much on the dissemination and exchange of data sets as on the publication of conclusions. Accurately tracking the lineage (origin and subsequent processing history) of scientific data sets is thus imperative for the complete documentation of scientific work. Researchers are effectively prevented from determining, preserving, or providing the lineage of the computational data products they use and create, however, because of the lack of a definitive model for lineage retrieval and a poor fit between current data management tools and scientific software. Based on a comprehensive survey of lineage research and previous prototypes, we present a metamodel to help identify and assess the basic components of systems that provide lineage retrieval for scientific data products.},
author = {Bose, Rajendra and Frew, James},
doi = {10.1145/1057977.1057978},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/p1-bose.pdf:pdf},
isbn = {0360-0300},
issn = {03600300},
journal = {ACM Computing Surveys},
number = {1},
pages = {1--28},
title = {{Lineage retrieval for scientific data processing: a survey}},
url = {http://portal.acm.org/citation.cfm?doid=1057977.1057978},
volume = {37},
year = {2005}
}
@article{Cheney2007,
author = {Cheney, James and Chiticariu, Laura and Tan, Wang-Chiew},
doi = {10.1561/1900000006},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/provenance.pdf:pdf},
isbn = {1931-7883, 1931-7891},
issn = {1931-7883},
journal = {Foundations and Trends in Databases},
number = {4},
pages = {379--474},
title = {{Provenance in Databases: Why, How, and Where}},
url = {http://www.nowpublishers.com/article/Details/DBS-006},
volume = {1},
year = {2007}
}
@article{Dave,
abstract = {Debugging the massive parallel computations that run in today's datacenters is hard, as they consist of thousands of tasks processing terabytes of data. It is especially hard in production settings, where performance overheads of more than a few percent are unacceptable. To address this challenge, we present Arthur, a new debugger that pro-vides a rich set of analysis tools at close to zero runtime overhead through selective replay of data flow applica-tions. Unlike previous replay debuggers, which add high overheads due to the need to log low-level nondetermin-istic events, Arthur takes advantage of the structure of large-scale data flow models (e.g., MapReduce), which split work into deterministic tasks for fault tolerance, to minimize its logging cost. We use selective replay to im-plement a variety of debugging features, including re-running any task in a single-process debugger; ad-hoc queries on computation state; and forward and backward tracing of records through the computation, which we achieve using a program transformation at replay time. We implement Arthur for Hadoop and Spark, and show that it can be used to find a variety of real bugs.},
author = {Dave, Ankur and Zaharia, Matei and Shenker, Scott and Stoica, Ion},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/spark/Arthur{\_}Rich{\_}Post-Facto{\_}Debugging{\_}for{\_}Pro.pdf:pdf},
title = {{Arthur: Rich Post-Facto Debugging for Production Analytics Applications}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.300.2760},
year = {2013}
}
@article{Avgerinos2014,
abstract = {We present MergePoint, a new binary-only symbolic execution system for large-scale and fully unassisted testing of commodity off-the-shelf (COTS) software. MergePoint introduces veritesting, a new technique that employs static symbolic execution to amplify the effect of dynamic symbolic execution. Veritesting allows MergePoint to find twice as many bugs, explore orders of magnitude more paths, and achieve higher code coverage than previous dynamic symbolic execution systems. MergePoint is currently running daily on a 100 node cluster analyzing 33,248 Linux binaries; has generated more than 15 billion SMT queries, 200 million test cases, 2,347,420 crashes, and found 11,687 bugs in 4,379 distinct applications.},
author = {Avgerinos, Thanassis and Rebert, Alexandre and Cha, Sang Kil and Brumley, David},
doi = {10.1145/2568225.2568293},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/p1083-avgerinos.pdf:pdf},
isbn = {9781450327565},
issn = {9781450327565},
journal = {Proceedings of the 36th International Conference on Software Engineering - ICSE 2014},
keywords = {symbolic execution,verification,veritesting},
pages = {1083--1094},
title = {{Enhancing Symbolic Execution with Veritesting}},
url = {http://dl.acm.org/citation.cfm?doid=2568225.2568293},
year = {2014}
}
@article{Armbrust2015,
abstract = {Spark SQL is a new module in Apache Spark that integrates relational processing with Spark's functional programming API. Built on our experience with Shark, Spark SQL lets Spark programmers leverage the benefits of relational processing (e.g. declarative queries and optimized storage), and lets SQL users call complex analytics libraries in Spark (e.g. machine learning). Compared to previous systems, Spark SQL makes two main additions. First, it offers much tighter integration between relational and procedural processing, through a declarative DataFrame API that integrates with procedural Spark code. Second, it includes a highly extensible optimizer, Catalyst, built using features of the Scala programming language, that makes it easy to add composable rules, control code generation, and define extension points. Using Catalyst, we have built a variety of features (e.g. schema inference for JSON, machine learning types, and query federation to external databases) tailored for the complex needs of modern data analysis. We see Spark SQL as an evolution of both SQL-on-Spark and of Spark itself, offering richer APIs and optimizations while keeping the benefits of the Spark programming model.},
author = {Armbrust, Michael and Ghodsi, Ali and Zaharia, Matei and Xin, Reynold S. and Lian, Cheng and Huai, Yin and Liu, Davies and Bradley, Joseph K. and Meng, Xiangrui and Kaftan, Tomer and Franklin, Michael J.},
doi = {10.1145/2723372.2742797},
file = {:home/omar/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Armbrust et al. - 2015 - Spark SQL.pdf:pdf},
isbn = {9781450327589},
issn = {07308078},
journal = {Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data - SIGMOD '15},
keywords = {data warehouse,databases,hadoop,machine learning,spark},
pages = {1383--1394},
title = {{Spark SQL}},
url = {http://dl.acm.org/citation.cfm?id=2723372.2742797},
year = {2015}
}
@article{Visser2005,
author = {Visser, Willem and Mehlitz, Peter},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/chp{\%}3A10.1007{\%}2F11537328{\_}5.pdf:pdf},
pages = {3639},
title = {{LNCS 3639 - Model Checking Programs with Java PathFinder}},
year = {2005}
}
@article{Christakis2016,
abstract = {Most techniques to detect program errors, such as testing, code reviews, and static program analysis, do not fully verify all possible executions of a program. They leave executions unverified when they do not check an execution path, check it under certain unjustified assumptions (such as the absence of arithmetic overflow), or fail to verify certain properties. In this paper, we present a technique to complement par-tial verification results by automatic test case generation. We annotate programs to reflect which executions have been verified, and under which assumptions. These annotations are then used to guide dynamic symbolic execution toward unverified program executions. Our main contribution is a code instrumentation that causes dynamic symbolic execu-tion to abort tests that lead to verified executions, to prune parts of the search space, and to prioritize tests that lead to unverified executions. We have implemented our tech-nique for the .NET static analyzer Clousot and the dynamic symbolic execution tool Pex. Compared to directly running Pex on the annotated programs without our instrumenta-tion, our approach produces smaller test suites (by up to 19.2{\%}), covers more unverified executions (by up to 7.1{\%}), and reduces testing time (by up to 52.4{\%}).},
author = {Christakis, Maria and M{\"{u}}ller, Peter and W{\"{u}}stholz, Valentin},
doi = {10.1145/2884781.2884843},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/p144-christakis.pdf:pdf},
isbn = {9781450339001},
issn = {02705257},
journal = {Proceedings of the 38th International Conference on Software Engineering - ICSE '16},
keywords = {dynamic symbolic execution,partial verification,program verification,static analysis,testing},
pages = {144--155},
title = {{Guiding dynamic symbolic execution toward unverified program executions}},
url = {http://dl.acm.org/citation.cfm?doid=2884781.2884843},
year = {2016}
}
@article{Raychev,
author = {Raychev, Veselin and Musuvathi, Madanlal and Mytkowicz, Todd},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/sosp15-symple.pdf:pdf},
isbn = {9781450338349},
number = {i},
title = {{Parallelizing User-Defined Aggregations using Symbolic Execution}}
}
@article{Person,
author = {Person, Suzette and Dwyer, Matthew B and Elbaum, Sebastian},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/p226-person.pdf:pdf},
isbn = {9781595939951},
keywords = {administration under grant num-,in part upon work,program differencing,software evolution,supported by the na-,symbolic execution,this material is based,tional aeronautics and space},
number = {1},
pages = {226--237},
title = {{Differential Symbolic Execution}}
}
@article{Interlandi2015,
abstract = {Debugging data processing logic in Data-Intensive Scalable Computing (DISC) systems is a difficult and time consuming effort. Today's DISC systems offer very little tooling for debugging programs, and as a result programmers spend countless hours collecting evidence (e.g., from log files) and performing trial and error debugging. To aid this effort, we built Titian, a library that enables data provenance— tracking data through transformations—in Apache Spark. Data scientists using the Titian Spark extension will be able to quickly identify the input data at the root cause of a potential bug or outlier result. Titian is built directly into the Spark platform and offers data provenance support at interactive speeds—orders-of-magnitude faster than alternative solutions—while minimally impacting Spark job performance; observed overheads for capturing data lineage rarely exceed 30{\%} above the baseline job execution time.},
author = {Interlandi, Matteo and Shah, Kshitij and Tetali, Sai Deep and Gulzar, Muhammad Ali and Yoo, Seunghyun and Kim, Miryung and Millstein, Todd and Condie, Tyson},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/spark/p216-interlandi.pdf:pdf},
issn = {2150-8097},
journal = {Proceedings of the VLDB Endowment},
number = {3},
pages = {216--227},
title = {{Titian: Data Provenance Support in Spark}},
url = {http://www.vldb.org/pvldb/vol9/p216-interlandi.pdf},
volume = {9},
year = {2015}
}
@article{Visser2004,
author = {Visser, Willem},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/chp{\%}3A10.1007{\%}2F978-3-540-24732-6{\_}13.pdf:pdf},
pages = {164--181},
title = {{Verification of Java Programs Using Symbolic Execution and Invariant Generation}},
year = {2004}
}
@article{Gulzar2016,
abstract = {Developers use cloud computing platforms to process a large quantity of data in parallel when developing big data analytics. Debugging the massive parallel computations that run in today's data-centers is time consuming and error-prone. To address this challenge, we design a set of interactive, real-time debugging primitives for big data processing in Apache Spark, the next generation data-intensive scalable cloud computing platform. This requires re-thinking the notion of step-through debugging in a traditional debugger such as gdb, because pausing the entire computation across distributed worker nodes causes significant delay and naively inspecting millions of records using a watchpoint is too time consuming for an end user. First, BIGDEBUG's simulated breakpoints and on-demand watchpoints allow users to selectively examine distributed, intermediate data on the cloud with little overhead. Second, a user can also pinpoint a crash-inducing record and selectively resume relevant sub-computations after a quick fix. Third, a user can determine the root causes of errors (or delays) at the level of individual records through a fine-grained data provenance capability. Our evaluation shows that BIGDEBUG scales to terabytes and its record-level tracing incurs less than 25{\%} overhead on average. It determines crash culprits orders of magnitude more accurately and provides up to 100{\%} time saving compared to the baseline replay debugger. The results show that BIGDEBUG supports debugging at interactive speeds with minimal performance impact.},
author = {Gulzar, Muhammad Ali and Interlandi, Matteo and Yoo, Seunghyun and Tetali, Sai Deep and Condie, Tyson and Millstein, Todd and Kim, Miryung},
doi = {10.1145/2884781.2884813},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/spark/p784-gulzar.pdf:pdf},
isbn = {9781450339001 | 9781450342056},
issn = {02705257},
journal = {Proceedings - International Conference on Software Engineering. International Conference on Software Engineering},
keywords = {Debugging, big data analytics, interactive tools,,able computing,big data analytics,data-intensive scal-,debugging,disc,fault localization and recovery,interactive tools},
pages = {784--795},
pmid = {27390389},
title = {{BigDebug: Debugging Primitives for Interactive Big Data Processing in Spark.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/27390389},
volume = {2016},
year = {2016}
}
@article{Daniel2014,
author = {Daniel, Jakub},
doi = {10.1145/2557833.2560573},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/p39c-daniel.pdf:pdf},
keywords = {java pathfinder,predicate abstraction,state space traversal},
number = {1},
pages = {1--5},
title = {{Predicate Abstraction in Java Pathfinder}},
volume = {39},
year = {2014}
}
@article{Meng2016,
archivePrefix = {arXiv},
arxivId = {arXiv:1505.06807v1},
author = {Meng, Xiangrui and Bradley, Joseph and Street, Spear and Francisco, San and Sparks, Evan and Berkeley, U C and Hall, Soda and Street, Spear and Francisco, San and Xin, Doris and Xin, Reynold and Franklin, Michael J and Berkeley, U C and Hall, Soda},
eprint = {arXiv:1505.06807v1},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/spark/p1235-meng.pdf:pdf},
journal = {Journal of Machine Learning Research},
pages = {1--7},
title = {{MLlib : Machine Learning in Apache Spark}},
volume = {17},
year = {2016}
}
@article{Zahariaa,
abstract = {Many “big data” applications must act on data in real time. Running these applications at ever-larger scales re- quires parallel platforms that automatically handle faults and stragglers. Unfortunately, current distributed stream processing models provide fault recovery in an expen- sive manner, requiring hot replication or long recovery times, and do not handle stragglers. We propose a new processing model, discretized streams (D-Streams), that overcomes these challenges. D-Streams enable a par- allel recovery mechanism that improves efficiency over traditional replication and backup schemes, and tolerates stragglers.We show that they support a rich set of oper- ators while attaining high per-node throughput similar to single-node systems, linear scaling to 100 nodes, sub- second latency, and sub-second fault recovery. Finally, D-Streams can easily be composed with batch and in- teractive query models like MapReduce, enabling rich applications that combine these modes. We implement D-Streams in a system called Spark Streaming.},
author = {Zaharia, Matei and Das, Tathagata and Li, Haoyuan and Hunter, Timothy and Shenker, Scott and Stoica, Ion},
doi = {10.1145/2517349.2522737},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/spark/p423-zaharia.pdf:pdf},
isbn = {9781450323888},
journal = {Sosp},
number = {1},
pages = {423--438},
title = {{Discretized Streams: Fault-Tolerant Streaming Computation at Scale}},
url = {http://dx.doi.org/10.1145/2517349.2522737},
year = {2013}
}
@article{Csallner,
author = {Csallner, Christoph and Fegaras, Leonidas},
file = {:home/omar/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Csallner, Fegaras - Unknown - New Ideas Track Testing MapReduce-Style Programs Categories and Subject Descriptors.pdf:pdf},
isbn = {9781450304436},
keywords = {MapReduce,dynamic symbolic execution,test generation},
title = {{New Ideas Track : Testing MapReduce-Style Programs Categories and Subject Descriptors}}
}
@article{Zaharia2012a,
abstract = {We present Resilient Distributed Datasets (RDDs), a distributed memory abstraction that lets programmers perform in-memory computations on large clusters in a fault-tolerant manner. RDDs are motivated by two types of applications that current computing frameworks handle inefficiently: iterative algorithms and interactive data mining tools. In both cases, keeping data in memory can improve performance by an order of magnitude. To achieve fault tolerance efficiently, RDDs provide a restricted form of shared memory, based on coarse-grained transformations rather than fine-grained updates to shared state. However, we show that RDDs are expressive enough to capture a wide class of computations, including recent specialized programming models for iterative jobs, such as Pregel, and new applications that these models do not capture. We have implemented RDDs in a system called Spark, which we evaluate through a variety of user applications and benchmarks.},
archivePrefix = {arXiv},
arxivId = {EECS-2011-82},
author = {Zaharia, Matei and Chowdhury, Mosharaf and Das, Tathagata and Dave, Ankur},
doi = {10.1111/j.1095-8649.2005.00662.x},
eprint = {EECS-2011-82},
file = {:home/omar/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zaharia et al. - 2012 - Resilient distributed datasets A fault-tolerant abstraction for in-memory cluster computing.pdf:pdf},
isbn = {978-931971-92-8},
issn = {00221112},
journal = {NSDI'12 Proceedings of the 9th USENIX conference on Networked Systems Design and Implementation},
pages = {2--2},
pmid = {2011},
title = {{Resilient distributed datasets: A fault-tolerant abstraction for in-memory cluster computing}},
url = {https://www.usenix.org/system/files/conference/nsdi12/nsdi12-final138.pdf},
year = {2012}
}
@article{Visser2008,
author = {Visser, Willem},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/chp{\%}3A10.1007{\%}2F978-3-540-77966-7{\_}5.pdf:pdf},
number = {2007},
pages = {17--18},
title = {{Symbolic Execution and Model Checking for Testing}},
volume = {4424},
year = {2008}
}
@article{Just2014,
abstract = {A good test suite is one that detects real faults. Because the set of faults in a program is usually unknowable, this definition is not useful to practitioners who are creating test suites, nor to researchers who are creating and evaluating tools that generate test suites. In place of real faults, testing research often uses mutants, which are artificial faults -- each one a simple syntactic variation -- that are systematically seeded throughout the program under test. Mutation analysis is appealing because large numbers of mutants can be automatically-generated and used to compensate for low quantities or the absence of known real faults. Unfortunately, there is little experimental evidence to support the use of mutants as a replacement for real faults. This paper investigates whether mutants are indeed a valid substitute for real faults, i.e., whether a test suite{\&}{\#}8217;s ability to detect mutants is correlated with its ability to detect real faults that developers have fixed. Unlike prior studies, these investigations also explicitly consider the conflating effects of code coverage on the mutant detection rate. Our experiments used 357 real faults in 5 open-source applications that comprise a total of 321,000 lines of code. Furthermore, our experiments used both developer-written and automatically-generated test suites. The results show a statistically significant correlation between mutant detection and real fault detection, independently of code coverage. The results also give concrete suggestions on how to improve mutation analysis and reveal some inherent limitations.},
author = {Just, Ren{\'{e}} and Jalali, Darioush and Inozemtseva, Laura and Ernst, Michael D and Holmes, Reid and Fraser, Gordon},
doi = {10.1145/2635868.2635929},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/p654-just.pdf:pdf},
isbn = {9781450330565},
journal = {Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering - FSE 2014},
keywords = {code coverage,mutation analysis,real faults,test effectiveness},
pages = {654--665},
title = {{Are mutants a valid substitute for real faults in software testing?}},
url = {http://www.linozemtseva.com/research/2014/tr/mutation/mutant{\_}tr.pdf{\%}5Cnhttp://dl.acm.org/citation.cfm?doid=2635868.2635929},
year = {2014}
}
@article{Salihoglu2015,
abstract = {We address the problem of debugging programs written for Pregel-like systems. After interviewing Giraph and GPS users, we devel-oped Graft. Graft supports the debugging cycle that users typically go through: (1) Users describe programmatically the set of vertices they are interested in inspecting. During execution, Graft captures the context information of these vertices across supersteps. (2) Us-ing Graft's GUI, users visualize how the values and messages of the captured vertices change from superstep to superstep,narrowing in suspicious vertices and supersteps. (3) Users replay the exact lines of the vertex.compute() function that executed for the sus-picious vertices and supersteps, by copying code that Graft gener-ates into their development environments' line-by-line debuggers. Graft also has features to construct end-to-end tests for Giraph pro-grams. Graft is open-source and fully integrated into Apache Gi-raph's main code base.},
author = {Salihoglu, Semih and Shin, Jaeho and Khanna, Vikesh and Truong, Ba Quan and Widom, Jennifer},
doi = {10.1145/2723372.2735353},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/p1403-salihoglu.pdf:pdf},
isbn = {978-1-4503-2758-9},
issn = {07308078},
journal = {Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data},
keywords = {debugging,distributed bulk synchronous parallel graph syste,distributed graph systems},
pages = {1403--1408},
title = {{Graft: A Debugging Tool For Apache Giraph}},
url = {http://doi.acm.org/10.1145/2723372.2735353},
year = {2015}
}
@article{Khurshid2003,
author = {Khurshid, Sarfraz and Visser, Willem},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/chp{\%}3A10.1007{\%}2F3-540-36577-X{\_}40.pdf:pdf},
pages = {553--568},
title = {{Generalized Symbolic Execution for Model Checking and Testing}},
year = {2003}
}
@article{Baldoni,
archivePrefix = {arXiv},
arxivId = {arXiv:1610.00502v1},
author = {Baldoni, Roberto and Coppa, Emilio and Demetrescu, Camil and Finocchi, Irene},
eprint = {arXiv:1610.00502v1},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/1610.00502.pdf:pdf},
number = {i},
pages = {1--39},
title = {{A Survey of Symbolic Execution Techniques}}
}
@article{Isard2007,
abstract = {Dryad is a general-purpose distributed execution engine for coarse-grain data-parallel applications. A Dryad applica- tion combines computational “vertices” with communica- tion “channels” to form a dataflow graph. Dryad runs the application by executing the vertices of this graph on a set of available computers, communicating as appropriate through files, TCP pipes, and shared-memory FIFOs. The vertices provided by the application developer are quite simple and are usually written as sequential programs with no thread creation or locking. Concurrency arises from Dryad scheduling vertices to run simultaneously on multi- ple computers, or on multiple CPU cores within a computer. The application can discover the size and placement of data at run time, and modify the graph as the computation pro- gresses to make efficient use of the available resources. Dryad is designed to scale from powerful multi-core sin- gle computers, through small clusters of computers, to data centers with thousands of computers. The Dryad execution engine handles all the difficult problems of creating a large distributed, concurrent application: scheduling the use of computers and their CPUs, recovering from communication or computer failures, and transporting data between ver- tices.},
author = {Isard, Michael and Budiu, Mihai and Yu, Yuan and Birrell, Andrew and Fetterly, Dennis},
doi = {10.1145/1272998.1273005},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/spark/p59-isard.pdf:pdf},
isbn = {978-1-59593-636-3},
issn = {01635980},
journal = {ACM SIGOPS Operating Systems Review},
keywords = {Distributed algorithm,cluster,concurrency,dataflow,distributed programming},
pages = {59--72},
title = {{Dryad: Distributed Data-Parallel Programs from Sequential Building Blocks}},
year = {2007}
}
@article{Lerda2001,
author = {Lerda, Flavio and Visser, Willem},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/p80-lerda.pdf:pdf},
pages = {80--102},
title = {{Addressing Dynamic Issues of Program Model Checking}},
year = {2001}
}
@article{Visser,
author = {Visser, Willem and Mehlitz, Peter},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/jpf-spin05.pdf:pdf},
pages = {1--28},
title = {{Willem Visser}}
}
@article{Sen,
author = {Sen, Koushik and Necula, George and Gong, Liang and Choi, Wontae},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/multise.pdf:pdf},
isbn = {9781450336758},
keywords = {concolic testing,jalangi,javascript,multise,symbolic execution,test generation,value summary},
title = {{MultiSE: Multi-Path Symbolic Execution using Value Summaries}}
}
@article{Venkataraman2016,
abstract = {R is a popular statistical programming language with a number of extensions that support data processing and machine learning tasks. However, interactive data analysis in R is usually limited as the R runtime is single threaded and can only process data sets that fit in a single machine's memory. We present SparkR, an R package that provides a frontend to Apache Spark and uses Spark's distributed computation engine to enable large scale data analysis from the R shell. We describe the main design goals of SparkR, discuss how the high-level DataFrame API enables scalable computation and present some of the key details of our implementation.},
archivePrefix = {arXiv},
arxivId = {arXiv:1508.06655v1},
author = {Venkataraman, Shivaram and Yang, Zongheng and Liu, Davies and Liang, Eric and Meng, Xiangrui and Xin, Reynold and Ghodsi, Ali and Franklin, Michael and Stoica, Ion and Zaharia, Matei},
doi = {10.1145/1235},
eprint = {arXiv:1508.06655v1},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/spark/p1099-venkataraman.pdf:pdf},
isbn = {9781450321389},
issn = {07308078},
journal = {Sigmod},
keywords = {4d trajectory management,importance sampling,motion planning,separation assurance,tactical planning},
pages = {4},
title = {{SparkR: Scaling R Programs with Spark}},
year = {2016}
}
@article{Zaharia2014,
abstract = {The past few years have seen a major change in computing systems, as growing data volumes and stalling processor speeds require more and more applications to scale out to distributed systems. Today, a myriad data sources, from the Internet to business operations to scientific instruments, produce large and valuable data streams. However, the processing capabilities of single machines have not kept up with the size of data, making it harder and harder to put to use. As a result, a growing number of organizations—not just web companies, but traditional enterprises and research labs—need to scale out their most important computations to clusters of hundreds of machines. At the same time, the speed and sophistication required of data processing have grown. In addition to simple queries, complex algorithms like machine learning and graph analysis are becoming common in many domains. And in addition to batch processing, streaming analysis of new real-time data sources is required to let organizations take timely action. Future computing platforms will need to not only scale out traditional workloads, but support these new applications as well. This dissertation proposes an architecture for cluster computing systems that can tackle emerging data processing workloads while coping with larger and larger scales. Whereas early cluster computing systems, like MapReduce, handled batch processing, our architecture also enables streaming and interactive queries, while keeping the scalability and fault tolerance of previous systems. And whereas most deployed systems only support simple one-pass computations (e.g., aggregation or SQL queries), ours also extends to the multi-pass algorithms required for more complex analytics (e.g., iterative algorithms for machine learning). Finally, unlike the specialized systems proposed for some of these workloads, our architecture allows these computations to be combined, enabling rich new applications that intermix, for example, streaming and batch processing, or SQL and complex analytics. We achieve these results through a simple extension to MapReduce that adds primitives for data sharing, called Resilient Distributed Datasets (RDDs). We show that this is enough to efficiently capture a wide range of workloads. We implement RDDs in the open source Spark system, which we evaluate using both synthetic benchmarks and real user applications. Spark matches or exceeds the performance of specialized systems in many application domains, while offering stronger fault tolerance guarantees and allowing these workloads to be combined. We explore the generality of RDDs from both a theoretical modeling perspective and a practical perspective to see why this extension can capture a wide range of previously disparate workloads.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Zaharia, Matei},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/spark/An Architecture for Fast and General Data Processing on Large Clusters.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
journal = {Berkeley Technical Report},
pages = {128},
pmid = {25246403},
title = {{An Architecture for Fast and General Data Processing on Large Clusters}},
year = {2014}
}
@article{Dean2004,
abstract = {MapReduce is a programming model and an associated implementation for processing and generating large data sets. Users specify a map function that processes a key/value pair to generate a set of intermediate key/value pairs, and a reduce function that merges all intermediate values associated with the same intermediate key. Many real world tasks are expressible in this model, as shown in the paper. Programs written in this functional style are automatically parallelized and executed on a large cluster of commodity machines. The run-time system takes care of the details of partitioning the input data, scheduling the program's execution across a set of machines, handling machine failures, and managing the required inter-machine communication. This allows programmers without any experience with parallel and distributed systems to easily utilize the resources of a large distributed system. Our implementation of MapReduce runs on a large cluster of commodity machines and is highly scalable: a typical MapReduce computation processes many terabytes of data on thousands of machines. Programmers find the system easy to use: hundreds of MapReduce programs have been implemented and upwards of one thousand MapReduce jobs are executed on Google's clusters every day.},
archivePrefix = {arXiv},
arxivId = {10.1.1.163.5292},
author = {Dean, Jeffrey and Ghemawat, Sanjay},
doi = {10.1145/1327452.1327492},
eprint = {10.1.1.163.5292},
file = {:home/omar/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dean, Ghemawat - 2004 - MapReduce Simplied Data Processing on Large Clusters.pdf:pdf},
isbn = {9781595936868},
issn = {00010782},
journal = {Proceedings of 6th Symposium on Operating Systems Design and Implementation},
pages = {137--149},
pmid = {11687618},
title = {{MapReduce: Simplied Data Processing on Large Clusters}},
year = {2004}
}
@article{,
doi = {10.1145/2382756.2382794},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/p37-3-khyzha.pdf:pdf},
keywords = {abstraction,java pathfinder,state space traversal},
number = {6},
pages = {1--5},
title = {{ACM SIGSOFT Software Engineering Notes Page 1 November 2012 Volume 37 Number 6}},
volume = {37},
year = {2012}
}
@article{Visser2003,
author = {Visser, Willem and Havelund, Klaus and Brat, Guillaume and Park, Seungjoon and Lerda, Flavio},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/art{\%}3A10.1023{\%}2FA{\%}3A1022920129859.pdf:pdf},
keywords = {abstraction,java,model checking,runtime analysis,static analysis,symmetry},
pages = {203--232},
title = {{Model Checking Programs}},
year = {2003}
}
@article{Mehlitz2008,
author = {Mehlitz, Peter C and Bushnell, David H and Gundy-burlet, Karen and Lowry, Michael and Person, Suzette and Pape, Mark},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/p15-pasareanu2.pdf:pdf},
isbn = {9781605580500},
keywords = {software model checking,symbolic execution,unit test-},
pages = {15--25},
title = {{Combining Unit-level Symbolic Execution and System-level Concrete Execution for Testing NASA Software ˘}},
year = {2008}
}
@article{Schutte2015,
abstract = {Recent years have seen the development of a multitude of tools for the security analysis of Android applications. A major deficit of current fully automated security analyses, however, is their inability to drive execution to interesting parts, such as where code is dynamically loaded or certain data is decrypted. In fact, security-critical or downright offensive code may not be reached at all by such analyses when dynamically checked conditions are not met by the analysis environment. To tackle this unsolved problem, we propose a tool combining static call path analysis with byte code instrumentation and a heuristic partial symbolic execution, which aims at executing interesting calls paths. It can systematically locate potentially security-critical code sections and instrument applications such that execution of these sections can be observed in a dynamic analysis. Among other use cases, this can be leveraged to force applications into revealing dynamically loaded code, a simple yet effective way to circumvent detection by security analysis software such as the Google Play Store's Bouncer. We illustrate the functionality of our tool by means of a simple logic bomb example and a real-life security vulnerability which is present in hunderd of apps and can still be actively exploited at this time.},
author = {Sch{\"{u}}tte, Julian and Fedler, Rafael and Titze, Dennis},
doi = {10.1109/AINA.2015.238},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/07098023.pdf:pdf},
isbn = {9781479979042},
issn = {1550445X},
journal = {Proceedings - International Conference on Advanced Information Networking and Applications, AINA},
keywords = {Android,Automated Analysis,Partial Symbolic Execution},
pages = {571--578},
title = {{ConDroid: Targeted dynamic analysis of android applications}},
volume = {2015-April},
year = {2015}
}
@article{Luckow2014,
author = {Luckow, Kasper S},
doi = {10.1145/2557833.2560571},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/p39a-luckow.pdf:pdf},
keywords = {debugging,java pathfinder,software en-,symbolic pathfinder},
number = {1},
pages = {1--5},
title = {{Symbolic PathFinder v7}},
volume = {39},
year = {2014}
}
@article{Rizzi2016,
abstract = {Our community constantly pushes the state-of-the-art by introduc-ing " new " techniques. These techniques often build on top of, and are compared against, existing systems that realize previously pub-lished techniques. The underlying assumption is that existing sys-tems correctly represent the techniques they implement. This pa-per examines that assumption through a study of KLEE, a pop-ular and well-cited tool in our community. We briefly describe six improvements we made to KLEE, none of which can be con-sidered " new " techniques, that provide order-of-magnitude perfor-mance gains. Given these improvements, we then investigate how the results and conclusions of a sample of papers that cite KLEE are affected. Our findings indicate that the strong emphasis on intro-ducing " new " techniques may lead to wasted effort, missed oppor-tunities for progress, an accretion of artifact complexity, and ques-tionable research conclusions (in our study, 27{\%} of the papers that depend on KLEE can be questioned). We conclude by revisiting initiatives that may help to realign the incentives to better support the foundations on which we build.},
archivePrefix = {arXiv},
arxivId = {arXiv:1508.06655v1},
author = {Rizzi, Eric F and Elbaum, Sebastian and Dwyer, Matthew B},
doi = {10.1145/2884781.2884835},
eprint = {arXiv:1508.06655v1},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/p132-rizzi.pdf:pdf},
isbn = {9781450339001},
issn = {02705257},
journal = {Proceedings of the 38th International Conference on Software Engineering - ICSE '16},
keywords = {replication,research incentives,research tools and infrastructure},
pages = {132--143},
title = {{On the techniques we create, the tools we build, and their misalignments}},
url = {http://dl.acm.org/citation.cfm?doid=2884781.2884835},
year = {2016}
}
@article{Luckow,
author = {Luckow, Kasper and Giannakopoulou, Dimitra and Howar, Falk and Isberner, Malte and Kahsai, Temesghen and Raman, Vishwanath},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/tacas2016-ldghikrr.pdf:pdf},
title = {{JDart : A Dynamic Symbolic Analysis Framework}}
}
@article{Armbrust2015a,
abstract = {Apache Spark is one of the most widely used open source processing engines for big data, with rich language-integrated APIs and a wide range of libraries. Over the past two years, our group has worked to deploy Spark to a wide range of organizations through consulting relationships as well as our hosted service, Databricks. We describe the main challenges and requirements that appeared in taking Spark to a wide set of users, and usability and performance improvements we have made to the engine in response.},
author = {Armbrust, Michael and Zaharia, Matei and Das, Tathagata and Davidson, Aaron and Ghodsi, Ali and Or, Andrew and Rosen, Josh and Stoica, Ion and Wendell, Patrick and Xin, Reynold},
doi = {10.14778/2824032.2824080},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/spark/p1840-armbrust.pdf:pdf},
issn = {21508097},
journal = {Proceedings of the VLDB Endowment},
number = {12},
pages = {1840--1843},
title = {{Scaling spark in the real world: performance and usability}},
url = {http://dl.acm.org/citation.cfm?id=2824032.2824080},
volume = {8},
year = {2015}
}
@article{Gvero2008,
abstract = {Java PathFinder (JPF) is an explicit-state model checker for Java programs. JPF implements a backtrackable Java Virtual Machine (JVM) that provides non-deterministic choices and control over thread scheduling. JPF is itself implemented in Java and runs on top of a host JVM. JPF represents the JVM state of the program being checked and performs three main operations on this state representation: bytecode execution, state backtracking, and state comparison. This paper summarizes four extensions that we have developed to the JPF state representation and operations. One extension provides a new functionality to JPF, and three extensions improve performance of JPF in various scenarios. Some of our code has already been included in publicly available JPF.},
author = {Gvero, Tihomir and Gligoric, Milos and Lauterburg, Steven},
doi = {10.1145/1368088.1368224},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/p863-gvero.pdf:pdf},
isbn = {9781605580791},
issn = {0270-5257},
journal = {Proceedings of the 30th international conference on Software engineering},
keywords = {bugs,checking properties,delta execution,java pathfinder,jpf,mixed execution,model checking},
pages = {863--866},
title = {{State extensions for java pathfinder}},
url = {http://portal.acm.org/citation.cfm?doid=1368088.1368224},
year = {2008}
}
@article{Havelund2000,
author = {Havelund, Klaus and Pressburger, Thomas and Technologies, Recom and Field, Moffett},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/art{\%}3A10.1007{\%}2Fs100090050043.pdf:pdf},
keywords = {assertions,concurrent programming,ing,java,model check-,program verification,spin},
pages = {366--381},
title = {{Model checking J}},
year = {2000}
}
@article{Dhok2016,
abstract = {Conventional concolic testing has been used to provide high coverage of paths in statically typed languages. While it has also been applied in the context of JavaScript (JS) programs, we observe that applying concolic testing to dynamically-typed JS programs involves tackling unique problems to en-sure scalability. In particular, a naive type-agnostic exten-sion of concolic testing to JS programs causes generation of large number of inputs. Consequently, many executions op-erate on undefined values and repeatedly explore same paths resulting in redundant tests, thus diminishing the scalability of testing drastically. In this paper, we address this problem by proposing a sim-ple yet effective approach that incorporates type-awareness intelligently in conventional concolic testing to reduce the number of generated inputs for JS programs. We extend our approach inter-procedurally by generating preconditions for each function that provide a summary of the relation be-tween the variable types and paths. Employing the function preconditions when testing reduces the number of inputs generated even further. We implement our ideas and validate it on a number of open-source JS programs (and libraries). For a significant percentage (on average 50{\%}) of the functions, we observe that type-aware concolic testing generates a minuscule per-centage (less than 5{\%}) of the inputs as compared to con-ventional concolic testing approach implemented on top of Jalangi. On average, this approach achieves over 97{\%} of line coverage and over 94{\%} of branch coverage for all the functions across all benchmarks. Moreover, the use of func-tion preconditions reduces the number of inputs generated by 50{\%}. We also demonstrate the use of function precon-ditions in automatically avoiding real crashes due to incor-rectly typed objects.},
archivePrefix = {arXiv},
arxivId = {arXiv:1508.06655v1},
author = {Dhok, Monika and Ramanathan, Murali Krishna and Sinha, Nishant},
doi = {10.1145/2884781.2884859},
eprint = {arXiv:1508.06655v1},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/p168-dhok.pdf:pdf},
isbn = {9781450339001},
issn = {9781450321389},
journal = {Proceedings of the 38th International Conference on Software Engineering - ICSE '16},
keywords = {JavaScript,dynamic analysis,testing},
pages = {168--179},
title = {{Type-aware concolic testing of JavaScript programs}},
url = {http://dl.acm.org/citation.cfm?doid=2884781.2884859},
year = {2016}
}
@article{Cadar2011,
author = {Cadar, Cristian and Godefroid, Patrice and Khurshid, Sarfraz and Pasareanu, Corina S and Sen, Koushik and Tillmann, Nikolai and Visser, Willem},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/p1066-cadar.pdf:pdf},
isbn = {9781450304450},
keywords = {dynamic test generation,generalized symbolic execution},
pages = {1066--1071},
title = {{Symbolic Execution for Software Testing in Practice – Preliminary Assessment}},
year = {2011}
}
@article{Filieri2013,
author = {Filieri, Antonio and Visser, Willem},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/p622-filieri.pdf:pdf},
isbn = {9781467330763},
pages = {622--631},
title = {{Reliability Analysis in Symbolic Pathfinder}},
year = {2013}
}
@article{Machiry2013,
abstract = {We present a system Dynodroid for generating relevant in- puts to unmodified Android apps. Dynodroid views an app as an event-driven program that interacts with its environ- ment by means of a sequence of events through the Android framework. By instrumenting the framework once and for all, Dynodroid monitors the reaction of an app upon each event in a lightweight manner, using it to guide the gener- ation of the next event to the app. Dynodroid also allows interleaving events from machines, which are better at gen- erating a large number of simple inputs, with events from humans, who are better at providing intelligent inputs. We evaluated Dynodroid on 50 open-source Android apps, and compared it with two prevalent approaches: users man- ually exercising apps, and Monkey, a popular fuzzing tool. Dynodroid, humans, and Monkey covered 55{\%}, 60{\%}, and 53{\%}, respectively, of each app's Java source code on average. Monkey took 20X more events on average than Dynodroid. Dynodroid also found 9 bugs in 7 of the 50 apps, and 6 bugs in 5 of the top 1,000 free apps on Google Play. Categories},
author = {Machiry, Aravind and Tahiliani, Rohan and Naik, Mayur},
doi = {10.1145/2491411.2491450},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/p224-machiry.pdf:pdf},
isbn = {9781450322379},
journal = {Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering - ESEC/FSE 2013},
keywords = {Android,GUI testing,testing event-driven programs},
pages = {224},
title = {{Dynodroid: an input generation system for Android apps}},
url = {http://dl.acm.org/citation.cfm?id=2491411.2491450},
year = {2013}
}
@article{Zaharia,
author = {Zaharia, B Y Matei and Xin, Reynold S and Wendell, Patrick and Das, Tathagata and Armbrust, Michael and Dave, Ankur and Meng, Xiangrui and Rosen, Josh and Venkataraman, Shivaram and Franklin, Michael J and Ghodsi, A L I and Gonzalez, Joseph and Shenker, Scott and Stoica, I O N and Of, T H E Growth},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/spark/p56-zaharia.pdf:pdf},
title = {{Contributed Articles}}
}
@article{Jeon2016a,
abstract = {Symbolic execution is a powerful program analysis tech-nique, but it is difficult to apply to programs built using frameworks such as Swing and Android, because the frame-work code itself is hard to symbolically execute. The stan-dard solution is to manually create a framework model that can be symbolically executed, but developing and maintain-ing a model is difficult and error-prone. In this paper, we present Pasket, a new system that takes a first step toward automatically generating Java framework models to support symbolic execution. Pasket's focus is on creating models by instantiating design patterns. Pasket takes as input class, method, and type information from the framework API, to-gether with tutorial programs that exercise the framework. From these artifacts and Pasket's internal knowledge of de-sign patterns, Pasket synthesizes a framework model whose behavior on the tutorial programs matches that of the origi-nal framework. We evaluated Pasket by synthesizing mod-els for subsets of Swing and Android. Our results show that the models derived by Pasket are sufficient to allow us to use off-the-shelf symbolic execution tools to analyze Java programs that rely on frameworks.},
author = {Jeon, Jinseong and Qiu, Xiaokang and Fetter-Degges, Jonathan and Foster, Jeffrey S. and Solar-Lezama, Armando},
doi = {10.1145/2884781.2884856},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/p156-jeon.pdf:pdf},
isbn = {9781450339001},
issn = {02705257},
journal = {Proceedings of the 38th International Conference on Software Engineering - ICSE '16},
keywords = {framework model,program synthesis,sketch,symbolic execution},
pages = {156--167},
title = {{Synthesizing framework models for symbolic execution}},
url = {http://dl.acm.org/citation.cfm?id=2884781.2884856},
year = {2016}
}
@article{VanderMerwe2014,
abstract = {JPF-Android is a model checking tool for Android applica- tions allowing them to be verified outside of an emulator on Java PathFinder (JPF). The Android applications are exe- cuted on a model of the Android software stack and their ex- ecution driven by simulating user and system input events. This paper follows from our previous work describing the design decisions and implementation of JPF-Android. Here we discuss the syntax and implementation of the scripting environment which is used to drive the execution of the An- droid application under analysis. It also focuses on a further extension to the tool used to automatically monitor the run- time behavior of Android applications. Categories},
author = {van der Merwe, Heila and van der Merwe, Brink and Visser, Willem},
doi = {10.1145/2557833.2560576},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/android/p40a-vandermerwe.pdf:pdf},
isbn = {9781457716393},
issn = {01635948},
journal = {ACM SIGSOFT Software Engineering Notes},
keywords = {Android application,Java PathFinder,Model Checking,Runtime monitoring,Testing,Verification},
number = {1},
pages = {1--5},
title = {{Execution and property specifications for JPF-android}},
url = {http://dl.acm.org/citation.cfm?doid=2557833.2560576},
volume = {39},
year = {2014}
}
@article{VanderMerwe2015,
author = {van der Merwe, Heila and Tkachuk, Oksana and Nel, Sean and van der Merwe, Brink and Visser, Willem},
doi = {10.1145/2830719.2830727},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/android/p34a-merwe.pdf:pdf},
issn = {01635948},
journal = {ACM SIGSOFT Software Engineering Notes},
keywords = {android application,environment generation,verification},
number = {6},
pages = {1--5},
title = {{Environment Modeling Using Runtime Values for JPF-Android}},
url = {http://dl.acm.org/citation.cfm?doid=2830719.2830727},
volume = {40},
year = {2015}
}
@article{Vissera,
author = {Visser, Willem and Khurshid, Sarfraz},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/p97-visser.pdf:pdf},
isbn = {1581138202},
keywords = {coverage,ing,model check-,red-black trees,symbolic execution,testing object-oriented programs},
pages = {97--107},
title = {{Test Input Generation with Java PathFinder}}
}
@article{VanderMerwe2012,
abstract = {Mobile application testing is a specialised and complex field. Due to mobile applications' event driven design and mo- bile runtime environment, there currently exist only a small number of tools to verify these applications. This paper describes the development of JPF-ANDROID, an Android application verification tool. JPF-ANDROID is built on Java Pathfinder, a Java model checking engine. JPF-ANDROID provides a simplified model of the Android framework on which an Android application can run. It then allows the user to script input events to drive the application flow. JPF-ANDROID provides a way to detect common property violations such as deadlocks and runtime exceptions in Android applications.},
author = {van der Merwe, Heila and van der Merwe, Brink and Visser, Willem},
doi = {10.1145/2382756.2382797},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/android/p38-2-vandermerwe.pdf:pdf},
isbn = {9781457716393},
issn = {01635948},
journal = {ACM SIGSOFT Software Engineering Notes},
keywords = {JPF,Java Pathfinder,android,automatic verification,mobile application,model checking,testing},
number = {6},
pages = {1},
title = {{Verifying Android applications using Java PathFinder}},
url = {http://dl.acm.org/citation.cfm?doid=2382756.2382797},
volume = {37},
year = {2012}
}
