@article{Armbrust2015a,
author = {Armbrust, Michael and Das, Tathagata and Davidson, Aaron and Ghodsi, Ali and Or, Andrew and Rosen, Josh and Stoica, Ion and Wendell, Patrick and Xin, Reynold and Zaharia, Matei},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/spark/p1840-armbrust.pdf:pdf},
number = {12},
pages = {1840--1843},
title = {{Scaling Spark in the Real World: Performance and Usability}},
volume = {8},
year = {2015}
}
@article{Schutte2015,
abstract = {Recent years have seen the development of a multitude of tools for the security analysis of Android applications. A major deficit of current fully automated security analyses, however, is their inability to drive execution to interesting parts, such as where code is dynamically loaded or certain data is decrypted. In fact, security-critical or downright offensive code may not be reached at all by such analyses when dynamically checked conditions are not met by the analysis environment. To tackle this unsolved problem, we propose a tool combining static call path analysis with byte code instrumentation and a heuristic partial symbolic execution, which aims at executing interesting calls paths. It can systematically locate potentially security-critical code sections and instrument applications such that execution of these sections can be observed in a dynamic analysis. Among other use cases, this can be leveraged to force applications into revealing dynamically loaded code, a simple yet effective way to circumvent detection by security analysis software such as the Google Play Store's Bouncer. We illustrate the functionality of our tool by means of a simple logic bomb example and a real-life security vulnerability which is present in hunderd of apps and can still be actively exploited at this time.},
author = {Sch{\"{u}}tte, Julian and Fedler, Rafael and Titze, Dennis},
doi = {10.1109/AINA.2015.238},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/07098023.pdf:pdf},
isbn = {9781479979042},
issn = {1550445X},
journal = {Proceedings - International Conference on Advanced Information Networking and Applications, AINA},
keywords = {Android,Automated Analysis,Partial Symbolic Execution},
pages = {571--578},
title = {{ConDroid: Targeted dynamic analysis of android applications}},
volume = {2015-April},
year = {2015}
}
@article{Gulzar2016,
abstract = {Developers use cloud computing platforms to process a large quantity of data in parallel when developing big data analytics. Debugging the massive parallel computations that run in today's data-centers is time consuming and error-prone. To address this challenge, we design a set of interactive, real-time debugging primitives for big data processing in Apache Spark, the next generation data-intensive scalable cloud computing platform. This requires re-thinking the notion of step-through debugging in a traditional debugger such as gdb, because pausing the entire computation across distributed worker nodes causes significant delay and naively inspecting millions of records using a watchpoint is too time consuming for an end user. First, BIGDEBUG's simulated breakpoints and on-demand watchpoints allow users to selectively examine distributed, intermediate data on the cloud with little overhead. Second, a user can also pinpoint a crash-inducing record and selectively resume relevant sub-computations after a quick fix. Third, a user can determine the root causes of errors (or delays) at the level of individual records through a fine-grained data provenance capability. Our evaluation shows that BIGDEBUG scales to terabytes and its record-level tracing incurs less than 25{\%} overhead on average. It determines crash culprits orders of magnitude more accurately and provides up to 100{\%} time saving compared to the baseline replay debugger. The results show that BIGDEBUG supports debugging at interactive speeds with minimal performance impact.},
author = {Gulzar, Muhammad Ali and Interlandi, Matteo and Yoo, Seunghyun and Tetali, Sai Deep and Condie, Tyson and Millstein, Todd and Kim, Miryung},
doi = {10.1145/2884781.2884813},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/spark/p784-gulzar.pdf:pdf},
isbn = {9781450339001 | 9781450342056},
issn = {02705257},
journal = {Proceedings - International Conference on Software Engineering. International Conference on Software Engineering},
keywords = {Debugging, big data analytics, interactive tools,,able computing,big data analytics,data-intensive scal-,debugging,disc,fault localization and recovery,interactive tools},
pages = {784--795},
pmid = {27390389},
title = {{BigDebug: Debugging Primitives for Interactive Big Data Processing in Spark.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/27390389},
volume = {2016},
year = {2016}
}
@article{Armbrust2015,
abstract = {Spark SQL is a new module in Apache Spark that integrates relational processing with Spark's functional programming API. Built on our experience with Shark, Spark SQL lets Spark programmers leverage the benefits of relational processing (e.g. declarative queries and optimized storage), and lets SQL users call complex analytics libraries in Spark (e.g. machine learning). Compared to previous systems, Spark SQL makes two main additions. First, it offers much tighter integration between relational and procedural processing, through a declarative DataFrame API that integrates with procedural Spark code. Second, it includes a highly extensible optimizer, Catalyst, built using features of the Scala programming language, that makes it easy to add composable rules, control code generation, and define extension points. Using Catalyst, we have built a variety of features (e.g. schema inference for JSON, machine learning types, and query federation to external databases) tailored for the complex needs of modern data analysis. We see Spark SQL as an evolution of both SQL-on-Spark and of Spark itself, offering richer APIs and optimizations while keeping the benefits of the Spark programming model.},
author = {Armbrust, Michael and Ghodsi, Ali and Zaharia, Matei and Xin, Reynold S. and Lian, Cheng and Huai, Yin and Liu, Davies and Bradley, Joseph K. and Meng, Xiangrui and Kaftan, Tomer and Franklin, Michael J.},
doi = {10.1145/2723372.2742797},
file = {:home/omar/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Armbrust et al. - 2015 - Spark SQL.pdf:pdf},
isbn = {9781450327589},
issn = {07308078},
journal = {Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data - SIGMOD '15},
keywords = {data warehouse,databases,hadoop,machine learning,spark},
pages = {1383--1394},
title = {{Spark SQL}},
url = {http://dl.acm.org/citation.cfm?id=2723372.2742797},
year = {2015}
}
@article{Dhok2016,
abstract = {Conventional concolic testing has been used to provide high coverage of paths in statically typed languages. While it has also been applied in the context of JavaScript (JS) programs, we observe that applying concolic testing to dynamically-typed JS programs involves tackling unique problems to en-sure scalability. In particular, a naive type-agnostic exten-sion of concolic testing to JS programs causes generation of large number of inputs. Consequently, many executions op-erate on undefined values and repeatedly explore same paths resulting in redundant tests, thus diminishing the scalability of testing drastically. In this paper, we address this problem by proposing a sim-ple yet effective approach that incorporates type-awareness intelligently in conventional concolic testing to reduce the number of generated inputs for JS programs. We extend our approach inter-procedurally by generating preconditions for each function that provide a summary of the relation be-tween the variable types and paths. Employing the function preconditions when testing reduces the number of inputs generated even further. We implement our ideas and validate it on a number of open-source JS programs (and libraries). For a significant percentage (on average 50{\%}) of the functions, we observe that type-aware concolic testing generates a minuscule per-centage (less than 5{\%}) of the inputs as compared to con-ventional concolic testing approach implemented on top of Jalangi. On average, this approach achieves over 97{\%} of line coverage and over 94{\%} of branch coverage for all the functions across all benchmarks. Moreover, the use of func-tion preconditions reduces the number of inputs generated by 50{\%}. We also demonstrate the use of function precon-ditions in automatically avoiding real crashes due to incor-rectly typed objects.},
archivePrefix = {arXiv},
arxivId = {arXiv:1508.06655v1},
author = {Dhok, Monika and Ramanathan, Murali Krishna and Sinha, Nishant},
doi = {10.1145/2884781.2884859},
eprint = {arXiv:1508.06655v1},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/p168-dhok.pdf:pdf},
isbn = {9781450339001},
issn = {9781450321389},
journal = {Proceedings of the 38th International Conference on Software Engineering - ICSE '16},
keywords = {JavaScript,dynamic analysis,testing},
pages = {168--179},
title = {{Type-aware concolic testing of JavaScript programs}},
url = {http://dl.acm.org/citation.cfm?doid=2884781.2884859},
year = {2016}
}
@article{Csallner,
author = {Csallner, Christoph and Fegaras, Leonidas},
file = {:home/omar/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Csallner, Fegaras - Unknown - New Ideas Track Testing MapReduce-Style Programs Categories and Subject Descriptors.pdf:pdf},
isbn = {9781450304436},
keywords = {MapReduce,dynamic symbolic execution,test generation},
title = {{New Ideas Track : Testing MapReduce-Style Programs Categories and Subject Descriptors}}
}
@article{Daniel2014,
author = {Daniel, Jakub},
doi = {10.1145/2557833.2560573},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/p39c-daniel.pdf:pdf},
keywords = {java pathfinder,predicate abstraction,state space traversal},
number = {1},
pages = {1--5},
title = {{Predicate Abstraction in Java Pathfinder}},
volume = {39},
year = {2014}
}
@article{Filieri2013,
author = {Filieri, Antonio and Visser, Willem},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/p622-filieri.pdf:pdf},
isbn = {9781467330763},
pages = {622--631},
title = {{Reliability Analysis in Symbolic Pathfinder}},
year = {2013}
}
@article{Machiry2013,
abstract = {We present a system Dynodroid for generating relevant in- puts to unmodified Android apps. Dynodroid views an app as an event-driven program that interacts with its environ- ment by means of a sequence of events through the Android framework. By instrumenting the framework once and for all, Dynodroid monitors the reaction of an app upon each event in a lightweight manner, using it to guide the gener- ation of the next event to the app. Dynodroid also allows interleaving events from machines, which are better at gen- erating a large number of simple inputs, with events from humans, who are better at providing intelligent inputs. We evaluated Dynodroid on 50 open-source Android apps, and compared it with two prevalent approaches: users man- ually exercising apps, and Monkey, a popular fuzzing tool. Dynodroid, humans, and Monkey covered 55{\%}, 60{\%}, and 53{\%}, respectively, of each app's Java source code on average. Monkey took 20X more events on average than Dynodroid. Dynodroid also found 9 bugs in 7 of the 50 apps, and 6 bugs in 5 of the top 1,000 free apps on Google Play. Categories},
author = {Machiry, Aravind and Tahiliani, Rohan and Naik, Mayur},
doi = {10.1145/2491411.2491450},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/p224-machiry.pdf:pdf},
isbn = {9781450322379},
journal = {Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering - ESEC/FSE 2013},
keywords = {Android,GUI testing,testing event-driven programs},
pages = {224},
title = {{Dynodroid: an input generation system for Android apps}},
url = {http://dl.acm.org/citation.cfm?id=2491411.2491450},
year = {2013}
}
@article{Interlandi2015,
abstract = {Debugging data processing logic in Data-Intensive Scalable Computing (DISC) systems is a difficult and time consuming effort. Today's DISC systems offer very little tooling for debugging programs, and as a result programmers spend countless hours collecting evidence (e.g., from log files) and performing trial and error debugging. To aid this effort, we built Titian, a library that enables data provenance— tracking data through transformations—in Apache Spark. Data scientists using the Titian Spark extension will be able to quickly identify the input data at the root cause of a potential bug or outlier result. Titian is built directly into the Spark platform and offers data provenance support at interactive speeds—orders-of-magnitude faster than alternative solutions—while minimally impacting Spark job performance; observed overheads for capturing data lineage rarely exceed 30{\%} above the baseline job execution time.},
author = {Interlandi, Matteo and Shah, Kshitij and Tetali, Sai Deep and Gulzar, Muhammad Ali and Yoo, Seunghyun and Kim, Miryung and Millstein, Todd and Condie, Tyson},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/spark/p216-interlandi.pdf:pdf},
issn = {2150-8097},
journal = {Proceedings of the VLDB Endowment},
number = {3},
pages = {216--227},
title = {{Titian: Data Provenance Support in Spark}},
url = {http://www.vldb.org/pvldb/vol9/p216-interlandi.pdf},
volume = {9},
year = {2015}
}
@article{,
doi = {10.1145/2382756.2382794},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/p37-3-khyzha.pdf:pdf},
keywords = {abstraction,java pathfinder,state space traversal},
number = {6},
pages = {1--5},
title = {{ACM SIGSOFT Software Engineering Notes Page 1 November 2012 Volume 37 Number 6}},
volume = {37},
year = {2012}
}
@article{Cadar2011,
author = {Cadar, Cristian and Godefroid, Patrice and Khurshid, Sarfraz and Pasareanu, Corina S and Sen, Koushik and Tillmann, Nikolai and Visser, Willem},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/p1066-cadar.pdf:pdf},
isbn = {9781450304450},
keywords = {dynamic test generation,generalized symbolic execution},
pages = {1066--1071},
title = {{Symbolic Execution for Software Testing in Practice – Preliminary Assessment}},
year = {2011}
}
@article{Visser2003,
author = {Visser, Willem and Havelund, Klaus and Brat, Guillaume and Park, Seungjoon and Lerda, Flavio},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/art{\%}3A10.1023{\%}2FA{\%}3A1022920129859.pdf:pdf},
keywords = {abstraction,java,model checking,runtime analysis,static analysis,symmetry},
pages = {203--232},
title = {{Model Checking Programs}},
year = {2003}
}
@article{Rizzi2016,
abstract = {Our community constantly pushes the state-of-the-art by introduc-ing " new " techniques. These techniques often build on top of, and are compared against, existing systems that realize previously pub-lished techniques. The underlying assumption is that existing sys-tems correctly represent the techniques they implement. This pa-per examines that assumption through a study of KLEE, a pop-ular and well-cited tool in our community. We briefly describe six improvements we made to KLEE, none of which can be con-sidered " new " techniques, that provide order-of-magnitude perfor-mance gains. Given these improvements, we then investigate how the results and conclusions of a sample of papers that cite KLEE are affected. Our findings indicate that the strong emphasis on intro-ducing " new " techniques may lead to wasted effort, missed oppor-tunities for progress, an accretion of artifact complexity, and ques-tionable research conclusions (in our study, 27{\%} of the papers that depend on KLEE can be questioned). We conclude by revisiting initiatives that may help to realign the incentives to better support the foundations on which we build.},
archivePrefix = {arXiv},
arxivId = {arXiv:1508.06655v1},
author = {Rizzi, Eric F and Elbaum, Sebastian and Dwyer, Matthew B},
doi = {10.1145/2884781.2884835},
eprint = {arXiv:1508.06655v1},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/p132-rizzi.pdf:pdf},
isbn = {9781450339001},
issn = {02705257},
journal = {Proceedings of the 38th International Conference on Software Engineering - ICSE '16},
keywords = {replication,research incentives,research tools and infrastructure},
pages = {132--143},
title = {{On the techniques we create, the tools we build, and their misalignments}},
url = {http://dl.acm.org/citation.cfm?doid=2884781.2884835},
year = {2016}
}
@article{Visser2005,
author = {Visser, Willem and Mehlitz, Peter},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/chp{\%}3A10.1007{\%}2F11537328{\_}5.pdf:pdf},
pages = {3639},
title = {{LNCS 3639 - Model Checking Programs with Java PathFinder}},
year = {2005}
}
@article{Visser2004,
author = {Visser, Willem},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/chp{\%}3A10.1007{\%}2F978-3-540-24732-6{\_}13.pdf:pdf},
pages = {164--181},
title = {{Verification of Java Programs Using Symbolic Execution and Invariant Generation}},
year = {2004}
}
@article{Dave,
abstract = {Debugging the massive parallel computations that run in today's datacenters is hard, as they consist of thousands of tasks processing terabytes of data. It is especially hard in production settings, where performance overheads of more than a few percent are unacceptable. To address this challenge, we present Arthur, a new debugger that pro-vides a rich set of analysis tools at close to zero runtime overhead through selective replay of data flow applica-tions. Unlike previous replay debuggers, which add high overheads due to the need to log low-level nondetermin-istic events, Arthur takes advantage of the structure of large-scale data flow models (e.g., MapReduce), which split work into deterministic tasks for fault tolerance, to minimize its logging cost. We use selective replay to im-plement a variety of debugging features, including re-running any task in a single-process debugger; ad-hoc queries on computation state; and forward and backward tracing of records through the computation, which we achieve using a program transformation at replay time. We implement Arthur for Hadoop and Spark, and show that it can be used to find a variety of real bugs.},
author = {Dave, Ankur and Zaharia, Matei and Shenker, Scott and Stoica, Ion},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/spark/Arthur{\_}Rich{\_}Post-Facto{\_}Debugging{\_}for{\_}Pro.pdf:pdf},
title = {{Arthur: Rich Post-Facto Debugging for Production Analytics Applications}}
}
@article{Mehlitz2008,
author = {Mehlitz, Peter C and Bushnell, David H and Gundy-burlet, Karen and Lowry, Michael and Person, Suzette and Pape, Mark},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/p15-pasareanu2.pdf:pdf},
isbn = {9781605580500},
keywords = {software model checking,symbolic execution,unit test-},
pages = {15--25},
title = {{Combining Unit-level Symbolic Execution and System-level Concrete Execution for Testing NASA Software ˘}},
year = {2008}
}
@article{Zaharia,
author = {Zaharia, B Y Matei and Xin, Reynold S and Wendell, Patrick and Das, Tathagata and Armbrust, Michael and Dave, Ankur and Meng, Xiangrui and Rosen, Josh and Venkataraman, Shivaram and Franklin, Michael J and Ghodsi, A L I and Gonzalez, Joseph and Shenker, Scott and Stoica, I O N and Of, T H E Growth},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/spark/p56-zaharia.pdf:pdf},
title = {contributed articles}
}
@article{Zaharia2014,
author = {Zaharia, Matei and Sciences, Computer},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/spark/An Architecture for Fast and General Data Processing on Large Clusters.pdf:pdf},
title = {{An Architecture for Fast and General Data Processing on Large Clusters}},
year = {2014}
}
@article{Salihoglu2015,
abstract = {We address the problem of debugging programs written for Pregel-like systems. After interviewing Giraph and GPS users, we devel-oped Graft. Graft supports the debugging cycle that users typically go through: (1) Users describe programmatically the set of vertices they are interested in inspecting. During execution, Graft captures the context information of these vertices across supersteps. (2) Us-ing Graft's GUI, users visualize how the values and messages of the captured vertices change from superstep to superstep,narrowing in suspicious vertices and supersteps. (3) Users replay the exact lines of the vertex.compute() function that executed for the sus-picious vertices and supersteps, by copying code that Graft gener-ates into their development environments' line-by-line debuggers. Graft also has features to construct end-to-end tests for Giraph pro-grams. Graft is open-source and fully integrated into Apache Gi-raph's main code base.},
author = {Salihoglu, Semih and Shin, Jaeho and Khanna, Vikesh and Truong, Ba Quan and Widom, Jennifer},
doi = {10.1145/2723372.2735353},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/p1403-salihoglu.pdf:pdf},
isbn = {978-1-4503-2758-9},
issn = {07308078},
journal = {Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data},
keywords = {debugging,distributed bulk synchronous parallel graph syste,distributed graph systems},
pages = {1403--1408},
title = {{Graft: A Debugging Tool For Apache Giraph}},
url = {http://doi.acm.org/10.1145/2723372.2735353},
year = {2015}
}
@article{Visser,
author = {Visser, Willem and Mehlitz, Peter},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/jpf-spin05.pdf:pdf},
pages = {1--28},
title = {{Willem Visser}}
}
@article{Visser2008,
author = {Visser, Willem},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/chp{\%}3A10.1007{\%}2F978-3-540-77966-7{\_}5.pdf:pdf},
number = {2007},
pages = {17--18},
title = {{Symbolic Execution and Model Checking for Testing}},
volume = {4424},
year = {2008}
}
@article{Csail,
author = {Csail, M I T},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/spark/p1099-venkataraman.pdf:pdf},
isbn = {9781450335317},
keywords = {r,spark,statistical computing},
pages = {1099--1104},
title = {{SparkR: Scaling R Programs with Spark}}
}
@article{Christakis2016,
abstract = {Most techniques to detect program errors, such as testing, code reviews, and static program analysis, do not fully verify all possible executions of a program. They leave executions unverified when they do not check an execution path, check it under certain unjustified assumptions (such as the absence of arithmetic overflow), or fail to verify certain properties. In this paper, we present a technique to complement par-tial verification results by automatic test case generation. We annotate programs to reflect which executions have been verified, and under which assumptions. These annotations are then used to guide dynamic symbolic execution toward unverified program executions. Our main contribution is a code instrumentation that causes dynamic symbolic execu-tion to abort tests that lead to verified executions, to prune parts of the search space, and to prioritize tests that lead to unverified executions. We have implemented our tech-nique for the .NET static analyzer Clousot and the dynamic symbolic execution tool Pex. Compared to directly running Pex on the annotated programs without our instrumenta-tion, our approach produces smaller test suites (by up to 19.2{\%}), covers more unverified executions (by up to 7.1{\%}), and reduces testing time (by up to 52.4{\%}).},
author = {Christakis, Maria and M{\"{u}}ller, Peter and W{\"{u}}stholz, Valentin},
doi = {10.1145/2884781.2884843},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/p144-christakis.pdf:pdf},
isbn = {9781450339001},
issn = {02705257},
journal = {Proceedings of the 38th International Conference on Software Engineering - ICSE '16},
keywords = {dynamic symbolic execution,partial verification,program verification,static analysis,testing},
pages = {144--155},
title = {{Guiding dynamic symbolic execution toward unverified program executions}},
url = {http://dl.acm.org/citation.cfm?doid=2884781.2884843},
year = {2016}
}
@article{Person,
author = {Person, Suzette and Dwyer, Matthew B and Elbaum, Sebastian},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/p226-person.pdf:pdf},
isbn = {9781595939951},
keywords = {administration under grant num-,in part upon work,program differencing,software evolution,supported by the na-,symbolic execution,this material is based,tional aeronautics and space},
number = {1},
pages = {226--237},
title = {{Differential Symbolic Execution}}
}
@article{Gvero2008,
abstract = {Java PathFinder (JPF) is an explicit-state model checker for Java programs. JPF implements a backtrackable Java Virtual Machine (JVM) that provides non-deterministic choices and control over thread scheduling. JPF is itself implemented in Java and runs on top of a host JVM. JPF represents the JVM state of the program being checked and performs three main operations on this state representation: bytecode execution, state backtracking, and state comparison. This paper summarizes four extensions that we have developed to the JPF state representation and operations. One extension provides a new functionality to JPF, and three extensions improve performance of JPF in various scenarios. Some of our code has already been included in publicly available JPF.},
author = {Gvero, Tihomir and Gligoric, Milos and Lauterburg, Steven},
doi = {10.1145/1368088.1368224},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/p863-gvero.pdf:pdf},
isbn = {9781605580791},
issn = {0270-5257},
journal = {Proceedings of the 30th international conference on Software engineering},
keywords = {bugs,checking properties,delta execution,java pathfinder,jpf,mixed execution,model checking},
pages = {863--866},
title = {{State extensions for java pathfinder}},
url = {http://portal.acm.org/citation.cfm?doid=1368088.1368224},
year = {2008}
}
@article{Lerda2001,
author = {Lerda, Flavio and Visser, Willem},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/p80-lerda.pdf:pdf},
pages = {80--102},
title = {{Addressing Dynamic Issues of Program Model Checking}},
year = {2001}
}
@article{Avgerinos2014,
abstract = {We present MergePoint, a new binary-only symbolic execution system for large-scale and fully unassisted testing of commodity off-the-shelf (COTS) software. MergePoint introduces veritesting, a new technique that employs static symbolic execution to amplify the effect of dynamic symbolic execution. Veritesting allows MergePoint to find twice as many bugs, explore orders of magnitude more paths, and achieve higher code coverage than previous dynamic symbolic execution systems. MergePoint is currently running daily on a 100 node cluster analyzing 33,248 Linux binaries; has generated more than 15 billion SMT queries, 200 million test cases, 2,347,420 crashes, and found 11,687 bugs in 4,379 distinct applications.},
author = {Avgerinos, Thanassis and Rebert, Alexandre and Cha, Sang Kil and Brumley, David},
doi = {10.1145/2568225.2568293},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/p1083-avgerinos.pdf:pdf},
isbn = {9781450327565},
issn = {9781450327565},
journal = {Proceedings of the 36th International Conference on Software Engineering - ICSE 2014},
keywords = {symbolic execution,verification,veritesting},
pages = {1083--1094},
title = {{Enhancing Symbolic Execution with Veritesting}},
url = {http://dl.acm.org/citation.cfm?doid=2568225.2568293},
year = {2014}
}
@article{Luckow2014,
author = {Luckow, Kasper S},
doi = {10.1145/2557833.2560571},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/p39a-luckow.pdf:pdf},
keywords = {debugging,java pathfinder,software en-,symbolic pathfinder},
number = {1},
pages = {1--5},
title = {{Symbolic PathFinder v7}},
volume = {39},
year = {2014}
}
@article{Khurshid2003,
author = {Khurshid, Sarfraz and Visser, Willem},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/chp{\%}3A10.1007{\%}2F3-540-36577-X{\_}40.pdf:pdf},
pages = {553--568},
title = {{Generalized Symbolic Execution for Model Checking and Testing}},
year = {2003}
}
@article{Meng2016,
author = {Meng, Xiangrui and Bradley, Joseph and Yavuz, Burak and Sparks, Evan and Venkataraman, Shivaram and Liu, Davies and Freeman, Jeremy},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/spark/p1235-meng.pdf:pdf},
pages = {1--7},
title = {{MLlib: Machine Learning in Apache Spark}},
volume = {17},
year = {2016}
}
@article{Just2014,
abstract = {A good test suite is one that detects real faults. Because the set of faults in a program is usually unknowable, this definition is not useful to practitioners who are creating test suites, nor to researchers who are creating and evaluating tools that generate test suites. In place of real faults, testing research often uses mutants, which are artificial faults -- each one a simple syntactic variation -- that are systematically seeded throughout the program under test. Mutation analysis is appealing because large numbers of mutants can be automatically-generated and used to compensate for low quantities or the absence of known real faults. Unfortunately, there is little experimental evidence to support the use of mutants as a replacement for real faults. This paper investigates whether mutants are indeed a valid substitute for real faults, i.e., whether a test suite{\&}{\#}8217;s ability to detect mutants is correlated with its ability to detect real faults that developers have fixed. Unlike prior studies, these investigations also explicitly consider the conflating effects of code coverage on the mutant detection rate. Our experiments used 357 real faults in 5 open-source applications that comprise a total of 321,000 lines of code. Furthermore, our experiments used both developer-written and automatically-generated test suites. The results show a statistically significant correlation between mutant detection and real fault detection, independently of code coverage. The results also give concrete suggestions on how to improve mutation analysis and reveal some inherent limitations.},
author = {Just, Ren{\'{e}} and Jalali, Darioush and Inozemtseva, Laura and Ernst, Michael D and Holmes, Reid and Fraser, Gordon},
doi = {10.1145/2635868.2635929},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/p654-just.pdf:pdf},
isbn = {9781450330565},
journal = {Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering - FSE 2014},
keywords = {code coverage,mutation analysis,real faults,test effectiveness},
pages = {654--665},
title = {{Are mutants a valid substitute for real faults in software testing?}},
url = {http://www.linozemtseva.com/research/2014/tr/mutation/mutant{\_}tr.pdf{\%}5Cnhttp://dl.acm.org/citation.cfm?doid=2635868.2635929},
year = {2014}
}
@article{Zahariaa,
author = {Zaharia, Matei and Das, Tathagata and Li, Haoyuan and Hunter, Timothy and Shenker, Scott and Stoica, Ion},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/spark/p423-zaharia.pdf:pdf},
isbn = {9781450323888},
number = {1},
pages = {423--438},
title = {{Discretized Streams: Fault-Tolerant Streaming Computation at Scale}}
}
@article{Havelund2000,
author = {Havelund, Klaus and Pressburger, Thomas and Technologies, Recom and Field, Moffett},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/art{\%}3A10.1007{\%}2Fs100090050043.pdf:pdf},
keywords = {assertions,concurrent programming,ing,java,model check-,program verification,spin},
pages = {366--381},
title = {{Model checking J}},
year = {2000}
}
@article{VanderMerwe2012,
abstract = {Mobile application testing is a specialised and complex field. Due to mobile applications' event driven design and mo- bile runtime environment, there currently exist only a small number of tools to verify these applications. This paper describes the development of JPF-ANDROID, an Android application verification tool. JPF-ANDROID is built on Java Pathfinder, a Java model checking engine. JPF-ANDROID provides a simplified model of the Android framework on which an Android application can run. It then allows the user to script input events to drive the application flow. JPF-ANDROID provides a way to detect common property violations such as deadlocks and runtime exceptions in Android applications.},
author = {van der Merwe, Heila and van der Merwe, Brink and Visser, Willem},
doi = {10.1145/2382756.2382797},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/android/p38-2-vandermerwe.pdf:pdf},
isbn = {9781457716393},
issn = {01635948},
journal = {ACM SIGSOFT Software Engineering Notes},
keywords = {JPF,Java Pathfinder,android,automatic verification,mobile application,model checking,testing},
number = {6},
pages = {1},
title = {{Verifying Android applications using Java PathFinder}},
url = {http://dl.acm.org/citation.cfm?doid=2382756.2382797},
volume = {37},
year = {2012}
}
@article{Vissera,
author = {Visser, Willem and Khurshid, Sarfraz},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/p97-visser.pdf:pdf},
isbn = {1581138202},
keywords = {coverage,ing,model check-,red-black trees,symbolic execution,testing object-oriented programs},
pages = {97--107},
title = {{Test Input Generation with Java PathFinder}}
}
@article{VanderMerwe2014,
abstract = {JPF-Android is a model checking tool for Android applica- tions allowing them to be verified outside of an emulator on Java PathFinder (JPF). The Android applications are exe- cuted on a model of the Android software stack and their ex- ecution driven by simulating user and system input events. This paper follows from our previous work describing the design decisions and implementation of JPF-Android. Here we discuss the syntax and implementation of the scripting environment which is used to drive the execution of the An- droid application under analysis. It also focuses on a further extension to the tool used to automatically monitor the run- time behavior of Android applications. Categories},
author = {van der Merwe, Heila and van der Merwe, Brink and Visser, Willem},
doi = {10.1145/2557833.2560576},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/android/p40a-vandermerwe.pdf:pdf},
isbn = {9781457716393},
issn = {01635948},
journal = {ACM SIGSOFT Software Engineering Notes},
keywords = {Android application,Java PathFinder,Model Checking,Runtime monitoring,Testing,Verification},
number = {1},
pages = {1--5},
title = {{Execution and property specifications for JPF-android}},
url = {http://dl.acm.org/citation.cfm?doid=2557833.2560576},
volume = {39},
year = {2014}
}
@article{Jeon2016a,
abstract = {Symbolic execution is a powerful program analysis tech-nique, but it is difficult to apply to programs built using frameworks such as Swing and Android, because the frame-work code itself is hard to symbolically execute. The stan-dard solution is to manually create a framework model that can be symbolically executed, but developing and maintain-ing a model is difficult and error-prone. In this paper, we present Pasket, a new system that takes a first step toward automatically generating Java framework models to support symbolic execution. Pasket's focus is on creating models by instantiating design patterns. Pasket takes as input class, method, and type information from the framework API, to-gether with tutorial programs that exercise the framework. From these artifacts and Pasket's internal knowledge of de-sign patterns, Pasket synthesizes a framework model whose behavior on the tutorial programs matches that of the origi-nal framework. We evaluated Pasket by synthesizing mod-els for subsets of Swing and Android. Our results show that the models derived by Pasket are sufficient to allow us to use off-the-shelf symbolic execution tools to analyze Java programs that rely on frameworks.},
author = {Jeon, Jinseong and Qiu, Xiaokang and Fetter-Degges, Jonathan and Foster, Jeffrey S. and Solar-Lezama, Armando},
doi = {10.1145/2884781.2884856},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/p156-jeon.pdf:pdf},
isbn = {9781450339001},
issn = {02705257},
journal = {Proceedings of the 38th International Conference on Software Engineering - ICSE '16},
keywords = {framework model,program synthesis,sketch,symbolic execution},
pages = {156--167},
title = {{Synthesizing framework models for symbolic execution}},
url = {http://dl.acm.org/citation.cfm?id=2884781.2884856},
year = {2016}
}
@article{VanderMerwe2015,
author = {van der Merwe, Heila and Tkachuk, Oksana and Nel, Sean and van der Merwe, Brink and Visser, Willem},
doi = {10.1145/2830719.2830727},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/android/p34a-merwe.pdf:pdf},
issn = {01635948},
journal = {ACM SIGSOFT Software Engineering Notes},
keywords = {android application,environment generation,verification},
number = {6},
pages = {1--5},
title = {{Environment Modeling Using Runtime Values for JPF-Android}},
url = {http://dl.acm.org/citation.cfm?doid=2830719.2830727},
volume = {40},
year = {2015}
}
