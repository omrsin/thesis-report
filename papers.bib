@phdthesis{Redelinghuys2012,
author = {Redelinghuys, Gideon},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/redelinghuys{\_}symbolic{\_}2012.pdf:pdf},
school = {University of Stellenbosch},
title = {{Symbolic String Execution}},
type = {Master Thesis},
year = {2012}
}
@article{Souza,
author = {Souza, Matheus and Borges, Mateus and Corina, S},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/CORAL- Solving Complex Constraints for Symbolic PathFinder.pdf:pdf},
title = {{CORAL: Solving Complex Constraints for Symbolic PathFinder}}
}
@article{Pasareanu2013,
abstract = {Symbolic PathFinder (SPF) is a software analysis tool that combines symbolic execution with model checking for automated test case generation and error detection in Java bytecode programs. In SPF, programs are executed on symbolic inputs representing multiple concrete inputs and the values of program variables are represented by expressions over those symbolic inputs. Constraints over these expressions are generated from the analysis of different paths through the program. The constraints are solved with off-the-shelf solvers to determine path feasibility and to generate test inputs. Model checking is used to explore different symbolic program executions, to systematically handle aliasing in the input data structures, and to analyze the multithreading present in the code. SPF incorporates techniques for handling input data structures, strings, and native calls to external libraries, as well as for solving complex mathematical constraints. We describe the tool and its application at NASA, in academia, and in industry. {\textcopyright} 2013 Springer Science+Business Media New York.},
author = {Pǎsǎreanu, Corina S. and Visser, Willem and Bushnell, David and Geldenhuys, Jaco and Mehlitz, Peter and Rungta, Neha},
doi = {10.1007/s10515-013-0122-2},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/pvbgmr13.pdf:pdf},
issn = {09288910},
journal = {Automated Software Engineering},
keywords = {Java,Model checking,Symbolic execution,Testing},
number = {3},
pages = {391--425},
title = {{Symbolic PathFinder: Integrating symbolic execution with model checking for Java bytecode analysis}},
volume = {20},
year = {2013}
}
@article{Anand2007,
abstract = {Explicit state model checking tools, such as Java PathFinder (JPF) [5, 12], are becoming effective in detecting subtle errors in complex concurrent software, but they typically can only deal with closed systems. We present here JPF–SE, a symbolic execution extension to Java PathFinder, that allows model checking of concurrent Java programs that take inputs from unbounded domains. JPF–SE enables symbolic execution of Java programs during explicit state model checking, which has the following unique characteristics: (a) checks the behavior of code using symbolic values that represent data for potentially infinite input domains, instead of enumerating and checking for small concrete data domains (b) takes advantage of the built-in capabilities of JPF to perform efficient search through the program state space: systematic analysis of different thread interleavings, heuristic search, state abstraction, symmetry and partial order reductions (c) enables modular analysis: checking programs on un-specified inputs enables the analysis of a compilation unit in isolation (d) automates test input generation for Java library classes [13] (e) uses annotations in the form of method specifications and loop invariants to prove light-weight properties of Java programs [8] and (f) uses a common interface to several well-known decision procedures to manipulate symbolic numeric constraints; JPF–SE can be extended easily to handle other decision procedures.},
author = {Anand, Saswat and Păsăreanu, Corina S. and Visser, Willem},
doi = {10.1007/978-3-540-71209-1},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/10.1.1.108.2565.pdf:pdf},
isbn = {978-3-540-71208-4},
issn = {03029743},
journal = {Tacas 2007},
pages = {134--138},
title = {{JPF–SE: A Symbolic Execution Extension to Java PathFinder}},
year = {2007}
}
@article{Pasareanu2010,
abstract = {Symbolic Pathfinder (SPF) combines symbolic execution with model checking and constraint solving for automated test case generation and error detection in Java programs with unspecified inputs. In this tool, programs are executed on symbolic inputs representing multiple concrete inputs. Values of variables are represented as constraints generated from the analysis of Java bytecode. The constraints are solved using off-the shelf solvers to generate test inputs guaranteed to achieve complex coverage criteria. SPF has been used successfully at NASA, in academia, and in industry.},
author = {Păsăreanu, Corina S. and Rungta, Neha},
doi = {10.1145/1858996.1859035},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/p179-pasareanu.pdf:pdf},
isbn = {9781450301169},
journal = {25th IEEE/ACM International Conference on Automated Software Engineering},
keywords = {automated test case generation,program analysis},
pages = {179--180},
title = {{Symbolic PathFinder: Symbolic Execution of Java Bytecode}},
url = {http://hdl.handle.net/2060/20110008292},
volume = {2},
year = {2010}
}
@article{Siegel2006,
abstract = {We present a method to verify the correctness of parallel programs that perform complex numerical computations, including computations involving floating-point arithmetic. The method requires that a sequential version of the program be provided, to serve as the specification for the parallel one. The key idea is to use model checking, together with symbolic execution, to establish the equivalence of the two programs.},
author = {Siegel, Stephen F and Mironova, Anastasia and Avrunin, George S and Clarke, Lori A},
doi = {10.1145/1146238.1146256},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/p157-siegel.pdf:pdf},
isbn = {1-59593-263-1},
journal = {Proceedings of the 2006 international symposium on Software testing and analysis},
keywords = {MPI,concurrency,finite state verification,floating-point,high performance computing,message passing interface,model checking,numerical program,parallel programming,spin,symbolic execution},
pages = {157--168},
title = {{Using model checking with symbolic execution to verify parallel numerical programs}},
url = {http://doi.acm.org/10.1145/1146238.1146256},
year = {2006}
}
@article{Bush2000,
author = {Bush, W R and Pincus, J P and Sielaff, D J},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/Bush{\_}et{\_}al-2000-Software-{\_}Practice{\_}and{\_}Experience.pdf:pdf},
journal = {Software Practice and Experience},
keywords = {program analysis,program error checking},
number = {November 1998},
pages = {775--802},
title = {{A static analyzer for finding dynamic programming errors}},
volume = {30},
year = {2000}
}
@article{Cadar2013,
abstract = {The challenges---and great promise---of modern symbolic execution techniques, and the tools to help implement them.},
author = {Cadar, Cristian and Sen, Koushik},
doi = {10.1145/2408776.2408795},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/p82-cadar.pdf:pdf},
isbn = {978-1-109-44370-7},
issn = {0001-0782},
journal = {Communications of the ACM},
number = {2},
pages = {82--90},
pmid = {16031144},
title = {{Symbolic execution for software testing: three decades later}},
url = {http://dl.acm.org/ft{\_}gateway.cfm?id=2408795{\&}type=html},
volume = {56},
year = {2013}
}
@article{Csallner2008,
abstract = {Dynamically discovering likely program invariants from concrete test executions has emerged as a highly promising software engineering technique. Dynamic invariant inference has the advantage of succinctly summarizing both "expected" program inputs and the subset of program behaviors that is normal under those inputs. In this paper, we introduce a technique that can drastically increase the relevance of inferred invariants, or reduce the size of the test suite required to obtain good invariants. Instead of falsifying invariants produced by pre-set patterns, we determine likely program invariants by combining the concrete execution of actual test cases with a simultaneous symbolic execution of the same tests. The symbolic execution produces abstract conditions over program variables that the concrete tests satisfy during their execution. In this way, we obtain the benefits of dynamic inference tools like Daikon: the inferred invariants correspond to the observed program behaviors. At the same time, however, our inferred invariants are much more suited to the program at hand than Daikon's hard-coded invariant patterns. The symbolic invariants are literally derived from the program text itself, with appropriate value substitutions as dictated by symbolic execution. We implemented our technique in the DySy tool, which utilizes a powerful symbolic execution and simplification engine. The results confirm the benefits of our approach. In Daikon's prime example benchmark, we infer the majority of the interesting Daikon invariants, while eliminating invariants that a human user is likely to consider irrelevant.},
author = {Csallner, Christoph and Tillmann, Nikolai and Smaragdakis, Yannis},
doi = {10.1145/1368088.1368127},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/04814139.pdf:pdf},
isbn = {9781605580791},
issn = {02705257},
journal = {Proceedings of the 13th international conference on Software engineering - ICSE '08},
pages = {281},
title = {{DySy: dynamic symbolic execution for invariant inference}},
url = {http://portal.acm.org/citation.cfm?doid=1368088.1368127},
year = {2008}
}
@article{Tomb2007,
abstract = {This paper describes an analysis approach based on a of static and dynamic techniques to ?nd run-time errors in Java code. It uses symbolic execution to ?nd constraints under which an error (e.g. a null pointer dereference, array out of bounds access, or assertion violation) may occur and then solves these constraints to ?nd test inputs that may expose the error. It only alerts the user to the possibility of a real error when it detects the expected exception during a program run. The analysis is customizable in two important ways. First, we can adjust how deeply to follow calls from each top-level method. Second, we can adjust the path termination tion for the symbolic execution engine to be either a bound on the path condition length or a bound on the number of times each instruction can be revisited. We evaluated the tool on a set of benchmarks from the literature as well as a number of real-world systems that range in size from a few thousand to 50,000 lines of code. The tool discovered all known errors in the benchmarks (as well as some not previously known) and reported on average 8 errors per 1000 lines of code for the industrial examples. In both cases the interprocedural call depth played little role in the error detection. That is, an intraprocedural analysis seems adequate for the class of errors we detect.},
author = {Tomb, Aaron and Brat, Guillaume and Visser, Willem},
doi = {10.1145/1273463.1273478},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/Variably{\_}interprocedural{\_}program{\_}analysis{\_}for{\_}runt.pdf:pdf},
isbn = {9781595937346},
journal = {Proceedings of the 2007 international symposium on Software testing and analysis ISSTA 07},
number = {January 2007},
pages = {97},
title = {{Variably interprocedural program analysis for runtime error detection}},
url = {http://portal.acm.org/citation.cfm?doid=1273463.1273478},
year = {2007}
}
@article{Allen1970,
abstract = {Any static, global analysis of the expression and data relationships in a program requires a knowledge of the control flow of the program. Since one of the primary reasons for doing such a global analysis in a compiler is to produce optimized programs, control flow analysis has been embedded in many compilers and has been described in several papers. An early paper by Prosser [5] described the use of Boolean matrices (or, more particularly, connectivity matrices) in flow analysis. The use of “dominance” relationships in flow analysis was first introduced by Prosser and much expanded by Lowry and Medlock [6]. References [6,8,9] describe compilers which use various forms of control flow analysis for optimization. Some recent developments in the area are reported in [4] and in [7]. The underlying motivation in all the different types of control flow analysis is the need to codify the flow relationships in the program. The codification may be in connectivity matrices, in predecessor-successor tables, in dominance lists, etc. Whatever the form, the purpose is to facilitate determining what the flow relationships are; in other words to facilitate answering such questions as: is this an inner loop?, if an expression is removed from the loop where can it be correctly and profitably placed?, which variable definitions can affect this use? In this paper the basic control flow relationships are expressed in a directed graph. Various graph constructs are then found and shown to codify interesting global relationships.},
annote = {NULL},
author = {Allen, Frances E.},
doi = {10.1145/800028.808479},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/p1-allen.pdf:pdf},
issn = {03621340},
journal = {Proceedings of ACM Symposium on Compiler Optimization},
pages = {1--19},
title = {{Control Flow Analysis}},
url = {http://portal.acm.org/citation.cfm?doid=800028.808479},
year = {1970}
}
@misc{Floyd1993,
abstract = {PURPOSE: The understanding of the site and nature of the cortical processing deficit in human amblyopia awaits the resolution of three fundamental questions about which there is, at present, much controversy: First, is area V1 affected as the present animal models would predict, but some imaging studies argue against? Second, how extensive is the loss of extrastriate function, and does it simply follow as a consequence of an impaired V1 input? Third, does the brain imaging deficit, be it striate or extrastriate, correlate with the well-documented psychophysical loss?-a fundamental issue on which previous brain imaging studies are divided. METHODS: A spatially broadband stimulus was used to determine the functional MRI responses from the different retinotopically identified visual cortical areas in a group of normal (n = 6) and a group of amblyopic (n = 11) observers. Responses were compared between the amblyopic and fellow fixing eyes of amblyopes and between the dominant and nondominant eyes of normal subjects, in central and peripheral parts of the visual field. Psychophysical acuity and contrast sensitivity was also measured and its correlation with the brain imaging deficit determined. RESULTS: V1 was affected in most but not all cases; the brain-imaging deficit involved extensive regions of extrastriate cortex and, at least with the stimuli used in the study, correlated with the V1 loss, suggesting a strong V1 influence; and neither the striate nor the extrastriate deficits correlated with the psychophysical contrast threshold losses at either high or low spatial frequencies. CONCLUSIONS: The results suggest that there are significant suprathreshold processing deficits that are not a consequence of the well-known threshold deficit. Our preoccupation over the past 30 years with the contrast detection deficit in amblyopia limited to the processing within a circumscribed part of V1 may have to be modified to include not only processing deficits for high-contrast stimuli but also the involvement of multiple extrastriate areas.},
annote = {NULL},
author = {Floyd, Robert W},
booktitle = {Mathematical aspects of computer science},
doi = {10.1007/978-94-011-1793-7_4},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/FloydMeaning.pdf:pdf},
isbn = {0821813196},
issn = {01460404},
number = {19-32},
pages = {65--81},
pmid = {17389487},
title = {{Assigning Meanings to Programs}},
url = {http://www.ams.org/mathscinet-getitem?mr=235771{\%}5Cnhttp://www.springerlink.com/index/10.1007/978-94-011-1793-7{\_}4},
volume = {19},
year = {1993}
}
@article{King1976,
abstract = {This paper describes the symbolic execution of programs. Instead of supplying the normal inputs to a program (e.g. numbers) one supplies symbols representing arbitrary values. The execution proceeds as in a normal execution except that values may be symbolic formulas over the input symbols. The difficult, yet interesting issues arise during the symbolic execution of conditional branch type statements. A particular system called EFFIGY which provides symbolic execution for program testing and debugging is also described. It interpretively executes programs written in a simple PL/I style programming language. It includes many standard debugging features, the ability to manage and to prove things about symbolic expressions, a simple program testing manager, and a program verifier. A brief discussion of the relationship between symbolic execution and program proving is also included.},
annote = {NULL},
author = {King, James C.},
doi = {10.1145/360248.360252},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/p385-king.pdf:pdf},
isbn = {0001-0782},
issn = {00010782},
journal = {Communications of the ACM},
keywords = {and phrases,pro-,symbolic execution},
number = {7},
pages = {385--394},
title = {{Symbolic execution and program testing}},
volume = {19},
year = {1976}
}
@article{Clarke1976,
abstract = {This paper describes a system that attempts to generate test data for programs written in ANSI Fortran. Given a path, the system symbolically executes the path and creates a set of constraints on the program's input variables. If the set of constraints is linear, linear programming techniques are employed to obtain a solution. A solution to the set of constraints is test data that will drive execution down the given path. If it can be determined that the set of constraints is inconsistent, then the given path is shown to be nonexecutable. To increase the chance of detecting some of the more common programming errors, artificial constraints are temporarily created that simulate error conditions and then an attempt is made to solve each augmented set of constraints. A symbolic representation of the program's output variables in terms of the program's input variables is also created. The symbolic representation is in a human readable form that facilitates error detection as well as being a possible aid in assertion generation and automatic program documentation.},
annote = {NULL},
author = {Clarke, L a},
doi = {10.1109/TSE.1976.233817},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/clarke76.pdf:pdf},
isbn = {0098-5589},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
keywords = {program validation,software reliability,symbolic execution,test data generation},
number = {3},
pages = {215--222},
title = {{A System to Generate Test Data and Symbolically Execute Programs}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1702368},
volume = {SE-2},
year = {1976}
}
@article{Hoare1969,
abstract = {In this paper an attempt is made to explore the logical foundations of computer programming by use of techniques which were first applied in the study of geometry and have later been extended to other branches of mathematics. This involves the elucidation of sets of axioms and rules of inference which can be used in proofs of the properties of computer programs. Examples are given of such axioms and rules, and a formal proof of a simple theorem is displayed. Finally, it is argued that important advantages, both theoretical and practical, may follow from a pursuance of these topics.},
annote = {NULL},
author = {Hoare, C. A. R.},
doi = {10.1145/363235.363259},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/p576-hoare.pdf:pdf},
isbn = {0001-0782},
issn = {00010782},
journal = {Communications of the ACM},
keywords = {0,20,21,22,23,24,4,5,and phrases,axiomatic method,cr category,design,formal language definition,machine-independent programming,program documentation,programming language,proofs of programs,theory of programming},
number = {10},
pages = {576--580},
title = {{An Axiomatic Basis for Computer Programming}},
volume = {12},
year = {1969}
}
@article{Lindholm2014,
abstract = {The Java Virtual Machine specified here is compatible with the Java SE 8 platform, and supports the Java programming language specified in The Java Language Specification, Java SE 8 Edition.},
author = {Lindholm, Tim and Yellin, Frank and Bracha, Gilad and Buckley, Alex},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/jvms8.pdf:pdf},
isbn = {978-0133260441},
journal = {Managing},
pages = {1--626},
title = {{The Java{\textregistered} Virtual Machine Specification}},
url = {http://docs.oracle.com/javase/specs/jvms/se8/jvms8.pdf},
year = {2014}
}
@article{Gosling2014,
abstract = {Written by the inventors of the technology, The Java Language Specification, Third Edition, is the definitive technical reference for the Java programming language. If you want to know the precise meaning of the language's constructs, this is the source for you.The book provides complete, accurate, and detailed coverage of the Java programming language. It provides full coverage of all new features added since the previous edition, including generics, annotations, asserts, autoboxing, enums, for-each loops, variable arity methods, and static import clauses.},
author = {{Gosling, James; Joy, Bill; Steele, Guy; Bracha, Gilad; Buckley}, Alex},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/jls8.pdf:pdf},
isbn = {0-321-24678-0},
journal = {Addison-Wesley},
pages = {688},
title = {{The Java{\textregistered} Language Specification - jls8.pdf}},
url = {https://docs.oracle.com/javase/specs/jls/se8/jls8.pdf},
year = {2014}
}
@article{Engle2012,
abstract = {Shark is a research data analysis system built on a novel coarse-grained distributed shared-memory abstraction. Shark marries query processing with deep data analysis, providing a unified system for easy data manipulation using SQL and pushing sophisticated analysis closer to data. It scales to thousands of nodes in a fault-tolerant manner. Shark can answer queries 40X faster than Apache Hive and run machine learning programs 25X faster than MapReduce programs in Apache Hadoop on large datasets.},
author = {Engle, Cliff and Lupher, Antonio and Xin, Reynold and Zaharia, Matei and Franklin, Michael J. and Shenker, Scott and Stoica, Ion},
doi = {10.1145/2213836.2213934},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/spark/p689-engle.pdf:pdf},
isbn = {9781450312479},
issn = {1450312470},
journal = {Proc. of the SIGMOD - Intl. Conf. on Management of Data},
keywords = {data warehouse,databases,machine learning,resilient distributed dataset,shark,spark},
pages = {689--692},
title = {{Shark: fast data analysis using coarse-grained distributed memory}},
url = {http://dl.acm.org/citation.cfm?id=2213836.2213934{\%}5Cnhttp://dl.acm.org/citation.cfm?doid=2213836.2213934},
year = {2012}
}
@article{Li2015,
abstract = {Spark has been increasingly adopted by industries in recent years for big data analysis by providing a fault tolerant, scalable and easy-to-use in memory abstraction. Moreover, the community has been actively developing a rich ecosystem around Spark, making it even more attractive. However, there is not yet a Spark specify benchmark existing in the literature to guide the development and cluster deployment of Spark to better fit resource demands of user applications. In this paper, we present SparkBench, a Spark specific benchmarking suite, which includes a comprehensive set of applications. SparkBench covers four main categories of applications, including machine learning, graph computation, SQL query and streaming applications. We also characterize the resource consumption, data flow and timing information of each application and evaluate the performance impact of a key configuration parameter to guide the design and optimization of Spark data analytic platform.},
author = {Li, Min and Tan, Jian and Wang, Yandong and Zhang, Li and Salapura, Valentina},
doi = {10.1145/2742854.2747283},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/benchmarks/a53-li.pdf:pdf},
isbn = {9781450333580},
journal = {Proceedings of the 12th ACM International Conference on Computing Frontiers - CF '15},
keywords = {benchmarking,cloud computing,evaluation,in memory data analytics,spark},
pages = {1--8},
title = {{SparkBench}},
url = {http://dl.acm.org/citation.cfm?doid=2742854.2747283{\%}5Cnhttp://dl.acm.org/citation.cfm?doid=2742854.2747283{\%}5Cnhttps://github.com/SparkTC/spark-bench{\%}5Cnhttps://bitbucket.org/lm0926/sparkbench{\%}5Cnhttp://people.cs.vt.edu/{~}butta/docs/tpctc2015-sparkbench.pdf},
year = {2015}
}
@article{Xin2013,
abstract = {From social networks to targeted advertising, big graphs capture the structure in data and are central to recent advances in machine learning and data mining. Unfortunately, directly applying existing data-parallel tools to graph computation tasks can be cumbersome and inefficient. The need for intuitive, scalable tools for graph computation has lead to the development of new graph-parallel systems (e.g. Pregel, PowerGraph) which are designed to efficiently execute graph algorithms. Unfortunately, these new graph-parallel systems do not address the challenges of graph construction and transformation which are often just as problematic as the subsequent computation. Furthermore, existing graph-parallel systems provide limited fault-tolerance and support for interactive data mining. We introduce GraphX, which combines the advantages of both data-parallel and graph-parallel systems by efficiently expressing graph computation within the Spark data-parallel framework. We leverage new ideas in distributed graph representation to efficiently distribute graphs as tabular data-structures. Similarly, we leverage advances in data-flow systems to exploit in-memory computation and fault-tolerance. We provide powerful new operations to simplify graph construction and transformation. Using these primitives we implement the PowerGraph and Pregel abstractions in less than 20 lines of code. Finally, by exploiting the Scala foundation of Spark, we enable users to interactively load, transform, and compute on massive graphs.},
archivePrefix = {arXiv},
arxivId = {1402.2394},
author = {Xin, Reynold S. and Gonzalez, Joseph E. and Franklin, Michael J. and Stoica, Ion},
doi = {10.1145/2484425.2484427},
eprint = {1402.2394},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/spark/a2-xin.pdf:pdf},
isbn = {9781450321884},
issn = {0002-9513},
journal = {First International Workshop on Graph Data Management Experiences and Systems - GRADES '13},
pages = {1--6},
title = {{GraphX: A Resilient Distributed Graph System on Spark}},
url = {http://dl.acm.org/citation.cfm?doid=2484425.2484427},
year = {2013}
}
@article{Bose2005,
abstract = {Scientific research relies as much on the dissemination and exchange of data sets as on the publication of conclusions. Accurately tracking the lineage (origin and subsequent processing history) of scientific data sets is thus imperative for the complete documentation of scientific work. Researchers are effectively prevented from determining, preserving, or providing the lineage of the computational data products they use and create, however, because of the lack of a definitive model for lineage retrieval and a poor fit between current data management tools and scientific software. Based on a comprehensive survey of lineage research and previous prototypes, we present a metamodel to help identify and assess the basic components of systems that provide lineage retrieval for scientific data products.},
author = {Bose, Rajendra and Frew, James},
doi = {10.1145/1057977.1057978},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/p1-bose.pdf:pdf},
isbn = {0360-0300},
issn = {03600300},
journal = {ACM Computing Surveys},
number = {1},
pages = {1--28},
title = {{Lineage retrieval for scientific data processing: a survey}},
url = {http://portal.acm.org/citation.cfm?doid=1057977.1057978},
volume = {37},
year = {2005}
}
@techreport{Xin2014,
author = {Xin, Reynold and Deyhim, Parviz and Ghodsi, Ali and Meng, Xiangrui and Zaharia, Matei},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/benchmarks/ApacheSpark2014.pdf:pdf},
keywords = {web},
title = {{GraySort on Apache Spark by Databricks}},
url = {http://sortbenchmark.org/ApacheSpark2014.pdf},
year = {2014}
}
@article{Cheney2007,
author = {Cheney, James and Chiticariu, Laura and Tan, Wang-Chiew},
doi = {10.1561/1900000006},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/provenance.pdf:pdf},
isbn = {1931-7883, 1931-7891},
issn = {1931-7883},
journal = {Foundations and Trends in Databases},
number = {4},
pages = {379--474},
title = {{Provenance in Databases: Why, How, and Where}},
url = {http://www.nowpublishers.com/article/Details/DBS-006},
volume = {1},
year = {2007}
}
@techreport{Wang,
abstract = {In this paper, we present NADSort, a sorting system on top of the distributed computing platform Apache Spark [1]. We report performance results of NADSort for Daytona CloudSort and Indy CloudSort benchmarks. NADSort is able to complete the 100TB Daytona CloudSort in 2983.33 seconds on random non-skewed datasets at an average cost of {\$}144.22 and 3057.67 seconds on skewed datasets at an average cost of {\$}147.82, and complete Indy CloudSort in 2983.33 seconds at an average cost of {\$}144.22.},
author = {Wang, Qian and Gu, Rong and Huang, Yihua and Xin, Reynold and Wu, Wei and Song, Jun and Xia, Junluan},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/benchmarks/NADSort2016.pdf:pdf},
pages = {1--6},
title = {{NADSort}},
url = {http://sortbenchmark.org/NADSort2016.pdf},
year = {2016}
}
@article{Pavlo2009,
abstract = {There is currently considerable enthusiasm around the MapReduce (MR) paradigm for large-scale data analysis 17. Although the basic control flow of this framework has existed in parallel SQL database management systems (DBMS) for over 20 years, some have called MR a dramatically new computing model 8, 17. In this paper, we describe and compare both paradigms. Furthermore, we evaluate both kinds of systems in terms of performance and development complexity. To this end, we define a benchmark consisting of a collection of tasks that we have run on an open source version of MR as well as on two parallel DBMSs. For each task, we measure each system's performance for various degrees of parallelism on a cluster of 100 nodes. Our results reveal some interesting trade-offs. Although the process to load data into and tune the execution of parallel DBMSs took much longer than the MR system, the observed performance of these DBMSs was strikingly better. We speculate about the causes of the dramatic performance difference and consider implementation concepts that future systems should take from both kinds of architectures.},
author = {Pavlo, a and Paulson, E and Rasin, a and Abadi, D J and DeWitt, D J and Madden, S and Stonebraker, M},
doi = {10.1145/1559845.1559865},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/benchmarks/p165-pavlo.pdf:pdf},
isbn = {9781605585512},
journal = {Distribution},
keywords = {Database Applications, Use Cases, Database Program},
number = {2},
pages = {165--178},
title = {{A Comparison of Approaches to Large-Scale Data Analysis}},
url = {http://portal.acm.org/citation.cfm?id=1559865},
volume = {12},
year = {2009}
}
@article{Chen2014,
abstract = {In this paper, we review the background and state-of-the-art of big data. We first introduce the general background of big data and review related technologies, such as could computing, Internet of Things, data centers, and Hadoop.We then focus on the four phases of the value chain of big data, i.e., data generation, data acquisition, data storage, and data analysis. For each phase, we introduce the general background, discuss the technical challenges, and review the latest advances. We finally examine the several representative applications of big data, including enterprise management, Internet of Things, online social networks, medial applications, collective intelligence, and smart grid. These discussions aimto provide a comprehensive overview and big-picture to readers of this exciting area. This survey is concluded with a discussion of open problems and future directions.},
author = {Chen, Min and Mao, Shiwen and Liu, Yunhao},
doi = {10.1007/s11036-013-0489-0},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/benchmarks/art{\%}3A10.1007{\%}2Fs11036-013-0489-0.pdf:pdf},
isbn = {1383-469X},
issn = {1383469X},
journal = {Mobile Networks and Applications},
keywords = {Big data,Big data analysis,Cloud computing,Data center,Hadoop,Internet of things,Smart grid},
number = {2},
pages = {171--209},
pmid = {1511170304},
title = {{Big data: A survey}},
volume = {19},
year = {2014}
}
@article{Wang2014,
author = {Wang, Lei and Zhan, Jianfeng and Luo, Chunjie and Zhu, Yuqing and Yang, Qiang and He, Yongqiang and Gao, Wanling and Jia, Zhen and Shi, Yingjie and Zhang, Shujie and Zheng, Chen and Lu, Gang and Zhan, Kent and Li, Xiaona and Qiu, Bizhu},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/benchmarks/06835958.pdf:pdf},
isbn = {9781479930975},
title = {{BigDataBench: a Big Data Benchmark Suite from Internet Services}},
year = {2014}
}
@article{Isard2007,
abstract = {Dryad is a general-purpose distributed execution engine for coarse-grain data-parallel applications. A Dryad applica- tion combines computational “vertices” with communica- tion “channels” to form a dataflow graph. Dryad runs the application by executing the vertices of this graph on a set of available computers, communicating as appropriate through files, TCP pipes, and shared-memory FIFOs. The vertices provided by the application developer are quite simple and are usually written as sequential programs with no thread creation or locking. Concurrency arises from Dryad scheduling vertices to run simultaneously on multi- ple computers, or on multiple CPU cores within a computer. The application can discover the size and placement of data at run time, and modify the graph as the computation pro- gresses to make efficient use of the available resources. Dryad is designed to scale from powerful multi-core sin- gle computers, through small clusters of computers, to data centers with thousands of computers. The Dryad execution engine handles all the difficult problems of creating a large distributed, concurrent application: scheduling the use of computers and their CPUs, recovering from communication or computer failures, and transporting data between ver- tices.},
author = {Isard, Michael and Budiu, Mihai and Yu, Yuan and Birrell, Andrew and Fetterly, Dennis},
doi = {10.1145/1272998.1273005},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/spark/p59-isard.pdf:pdf},
isbn = {978-1-59593-636-3},
issn = {01635980},
journal = {ACM SIGOPS Operating Systems Review},
keywords = {Distributed algorithm,cluster,concurrency,dataflow,distributed programming},
pages = {59--72},
title = {{Dryad: Distributed Data-Parallel Programs from Sequential Building Blocks}},
year = {2007}
}
@article{Luckow,
author = {Luckow, Kasper and Giannakopoulou, Dimitra and Howar, Falk and Isberner, Malte and Kahsai, Temesghen and Raman, Vishwanath},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/tacas2016-ldghikrr.pdf:pdf},
title = {{JDart : A Dynamic Symbolic Analysis Framework}}
}
@article{Sen,
author = {Sen, Koushik and Necula, George and Gong, Liang and Choi, Wontae},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/multise.pdf:pdf},
isbn = {9781450336758},
keywords = {concolic testing,jalangi,javascript,multise,symbolic execution,test generation,value summary},
title = {{MultiSE: Multi-Path Symbolic Execution using Value Summaries}}
}
@article{Raychev,
author = {Raychev, Veselin and Musuvathi, Madanlal and Mytkowicz, Todd},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/sosp15-symple.pdf:pdf},
isbn = {9781450338349},
number = {i},
title = {{Parallelizing User-Defined Aggregations using Symbolic Execution}}
}
@article{Baldoni,
archivePrefix = {arXiv},
arxivId = {arXiv:1610.00502v1},
author = {Baldoni, Roberto and Coppa, Emilio and Demetrescu, Camil and Finocchi, Irene},
eprint = {arXiv:1610.00502v1},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/1610.00502.pdf:pdf},
number = {i},
pages = {1--39},
title = {{A Survey of Symbolic Execution Techniques}}
}
@inproceedings{Visser2005,
author = {Visser, Willem and Mehlitz, Peter C},
booktitle = {Proceedings of the 12th International SPIN Workshop on Model Checking Software, San Francisco, CA, USA, August 22-24, 2005},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/chp{\%}3A10.1007{\%}2F11537328{\_}5.pdf:pdf},
issn = {03029743},
pages = {27},
title = {{Model Checking Programs with Java PathFinder}},
volume = {3639},
year = {2005}
}
@article{Venkataraman2016,
abstract = {R is a popular statistical programming language with a number of extensions that support data processing and machine learning tasks. However, interactive data analysis in R is usually limited as the R runtime is single threaded and can only process data sets that fit in a single machine's memory. We present SparkR, an R package that provides a frontend to Apache Spark and uses Spark's distributed computation engine to enable large scale data analysis from the R shell. We describe the main design goals of SparkR, discuss how the high-level DataFrame API enables scalable computation and present some of the key details of our implementation.},
archivePrefix = {arXiv},
arxivId = {arXiv:1508.06655v1},
author = {Venkataraman, Shivaram and Yang, Zongheng and Liu, Davies and Liang, Eric and Meng, Xiangrui and Xin, Reynold and Ghodsi, Ali and Franklin, Michael and Stoica, Ion and Zaharia, Matei},
doi = {10.1145/1235},
eprint = {arXiv:1508.06655v1},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/spark/p1099-venkataraman.pdf:pdf},
isbn = {9781450321389},
issn = {07308078},
journal = {Sigmod},
keywords = {4d trajectory management,importance sampling,motion planning,separation assurance,tactical planning},
pages = {4},
title = {{SparkR: Scaling R Programs with Spark}},
year = {2016}
}
@article{Filieri2013,
author = {Filieri, Antonio and Visser, Willem},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/p622-filieri.pdf:pdf},
isbn = {9781467330763},
pages = {622--631},
title = {{Reliability Analysis in Symbolic Pathfinder}},
year = {2013}
}
@article{Gvero2008,
abstract = {Java PathFinder (JPF) is an explicit-state model checker for Java programs. JPF implements a backtrackable Java Virtual Machine (JVM) that provides non-deterministic choices and control over thread scheduling. JPF is itself implemented in Java and runs on top of a host JVM. JPF represents the JVM state of the program being checked and performs three main operations on this state representation: bytecode execution, state backtracking, and state comparison. This paper summarizes four extensions that we have developed to the JPF state representation and operations. One extension provides a new functionality to JPF, and three extensions improve performance of JPF in various scenarios. Some of our code has already been included in publicly available JPF.},
author = {Gvero, Tihomir and Gligoric, Milos and Lauterburg, Steven},
doi = {10.1145/1368088.1368224},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/p863-gvero.pdf:pdf},
isbn = {9781605580791},
issn = {0270-5257},
journal = {Proceedings of the 30th international conference on Software engineering},
keywords = {bugs,checking properties,delta execution,java pathfinder,jpf,mixed execution,model checking},
pages = {863--866},
title = {{State extensions for java pathfinder}},
url = {http://portal.acm.org/citation.cfm?doid=1368088.1368224},
year = {2008}
}
@article{Cadar2011,
author = {Cadar, Cristian and Godefroid, Patrice and Khurshid, Sarfraz and Pasareanu, Corina S and Sen, Koushik and Tillmann, Nikolai and Visser, Willem},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/p1066-cadar.pdf:pdf},
isbn = {9781450304450},
keywords = {dynamic test generation,generalized symbolic execution},
pages = {1066--1071},
title = {{Symbolic Execution for Software Testing in Practice – Preliminary Assessment}},
year = {2011}
}
@article{Luckow2014,
author = {Luckow, Kasper S and Păsăreanu, Corina S.},
doi = {10.1145/2557833.2560571},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/p39a-luckow.pdf:pdf},
issn = {0163-5948},
journal = {SIGSOFT Softw. Eng. Notes},
keywords = {Java PathFinder,debugging,software engineering,symbolic pathFinder},
number = {1},
pages = {1--5},
title = {{Symbolic PathFinder V7}},
url = {http://doi.acm.org/10.1145/2557833.2560571},
volume = {39},
year = {2014}
}
@article{Khurshid2003,
author = {Khurshid, Sarfraz and Păsăreanu, Corina S. and Visser, Willem},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/chp{\%}3A10.1007{\%}2F3-540-36577-X{\_}40.pdf:pdf},
pages = {553--568},
title = {{Generalized Symbolic Execution for Model Checking and Testing}},
year = {2003}
}
@article{Mehlitz2008,
abstract = {We describe an approach to testing complex safety critical software that combines unit-level symbolic execution and system-level concrete execution for generating test cases that satisfy user-specified testing criteria. We have developed Symbolic Java PathFinder, a symbolic execution framework that implements a non-standard bytecode interpreter on top of the Java PathFinder model checking tool. The framework propagates the symbolic information via attributes associated with the program data. Furthermore, we use two techniques that leverage system-level concrete program executions to gather information about a unit's input to improve the precision of the unit-level test case generation. We applied our approach to testing a prototype NASA flight software component. Our analysis helped discover a serious bug that resulted in design changes to the software. Although we give our presentation in the context of a NASA project, we believe that our work is relevant for other critical systems that require thorough testing.},
author = {Păsăreanu, Corina S. and Mehlitz, Peter C and Bushnell, David H and Gundy-Burlet, Karen and Lowry, Michael and Person, Suzette and Pape, Mark},
doi = {10.1145/1390630.1390635},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/p15-pasareanu2.pdf:pdf},
isbn = {9781605580500},
journal = {Proceedings of the 2008 international symposium on Software testing and analysis ISSTA 08},
keywords = {software model checking,symbolic execution,unit test},
pages = {15--26},
title = {{Combining unit-level symbolic execution and system-level concrete execution for testing nasa software}},
url = {http://portal.acm.org/citation.cfm?doid=1390630.1390635},
year = {2008}
}
@article{Lerda2001,
author = {Lerda, Flavio and Visser, Willem},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/p80-lerda.pdf:pdf},
pages = {80--102},
title = {{Addressing Dynamic Issues of Program Model Checking}},
year = {2001}
}
@article{Visser2004a,
abstract = {We show how model checking and symbolic execution can be used to generate test inputs to achieve structural coverage of code that manipulates complex data structures. We focus on obtaining branch-coverage during unit testing of some of the core methods of the red-black tree implementation in the Java TreeMap library, using the Java PathFinder model checker. Three different test generation techniques will be introduced and compared, namely, straight model checking of the code, model checking used in a black-box fashion to generate all inputs up to a fixed size, and lastly, model checking used during white-box test input generation. The main contribution of this work is to show how efficient white-box test input generation can be done for code manipulating complex data, taking into account complex method preconditions.},
author = {Visser, Willem and Păsăreanu, Corina S. and Khurshid, Sarfraz},
doi = {10.1145/1013886.1007526},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/p97-visser.pdf:pdf},
isbn = {1581138202},
issn = {01635948},
journal = {ACM SIGSOFT Software Engineering Notes},
keywords = {coverage,ing,model check-,red-black trees,stat,static analysi,static analysis,symbolic execution,testing object-oriented programs},
number = {4},
pages = {97},
pmid = {9223372036854775808},
title = {{Test Input Generation with Java PathFinder}},
volume = {29},
year = {2004}
}
@article{VanderMerwe2014,
abstract = {JPF-Android is a model checking tool for Android applica- tions allowing them to be verified outside of an emulator on Java PathFinder (JPF). The Android applications are exe- cuted on a model of the Android software stack and their ex- ecution driven by simulating user and system input events. This paper follows from our previous work describing the design decisions and implementation of JPF-Android. Here we discuss the syntax and implementation of the scripting environment which is used to drive the execution of the An- droid application under analysis. It also focuses on a further extension to the tool used to automatically monitor the run- time behavior of Android applications. Categories},
author = {van der Merwe, Heila and van der Merwe, Brink and Visser, Willem},
doi = {10.1145/2557833.2560576},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/android/p40a-vandermerwe.pdf:pdf},
isbn = {9781457716393},
issn = {01635948},
journal = {ACM SIGSOFT Software Engineering Notes},
keywords = {Android application,Java PathFinder,Model Checking,Runtime monitoring,Testing,Verification},
number = {1},
pages = {1--5},
title = {{Execution and property specifications for JPF-android}},
url = {http://dl.acm.org/citation.cfm?doid=2557833.2560576},
volume = {39},
year = {2014}
}
@article{VanderMerwe2015,
author = {van der Merwe, Heila and Tkachuk, Oksana and Nel, Sean and van der Merwe, Brink and Visser, Willem},
doi = {10.1145/2830719.2830727},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/android/p34a-merwe.pdf:pdf},
issn = {01635948},
journal = {ACM SIGSOFT Software Engineering Notes},
keywords = {android application,environment generation,verification},
number = {6},
pages = {1--5},
title = {{Environment Modeling Using Runtime Values for JPF-Android}},
url = {http://dl.acm.org/citation.cfm?doid=2830719.2830727},
volume = {40},
year = {2015}
}
@article{Visser,
author = {Visser, Willem and Mehlitz, Peter},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/jpf-spin05.pdf:pdf},
pages = {1--28},
title = {{Willem Visser}}
}
@article{Zaharia,
author = {Zaharia, B Y Matei and Xin, Reynold S and Wendell, Patrick and Das, Tathagata and Armbrust, Michael and Dave, Ankur and Meng, Xiangrui and Rosen, Josh and Venkataraman, Shivaram and Franklin, Michael J and Ghodsi, A L I and Gonzalez, Joseph and Shenker, Scott and Stoica, I O N and Of, T H E Growth},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/spark/p56-zaharia.pdf:pdf},
title = {{Contributed Articles}}
}
@article{Havelund2000,
abstract = {Abstract.   This paper describes a translator called Java$\backslash$nPathFinder (Jpf), which translates from Java to Promela, the modeling$\backslash$nlanguage of the Spin model checker. Jpf translates a given Java program$\backslash$ninto a Promela model, which then can be model checked using Spin.$\backslash$nThe Java program may contain assertions, which are translated into$\backslash$nsimilar assertions in the Promela model. The Spin model checker will$\backslash$nthen look for deadlocks and violations of any stated assertions.$\backslash$nJpf generates a Promela model with the same state space characteristics$\backslash$nas the Java program. Hence, the Java program must have a finite and$\backslash$ntractable state space. This work should be seen in a broader attempt$\backslash$nto make formal methods applicable within NASA's areas such as space,$\backslash$naviation, and robotics. The work is a continuation of an effort to$\backslash$nformally analyze, using Spin, a multi-threaded operating system for$\backslash$nthe Deep-Space 1 space craft, and of previous work in applying existing$\backslash$nmodel checkers and theorem provers to real applications.},
author = {Havelund, Klaus and Pressburger, Thomas},
doi = {10.1007/s100090050043},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/art{\%}3A10.1007{\%}2Fs100090050043.pdf:pdf},
issn = {14332779},
journal = {International Journal on Software Tools for Technology Transfer (STTT)},
keywords = {assertions,concurrent programming,ing,java,model check-,program verification,spin},
number = {4},
pages = {366--381},
title = {{Model checking JAVA programs using JAVA PathFinder}},
url = {http://dx.doi.org/10.1007/s100090050043},
volume = {2},
year = {2000}
}
@article{Zahariaa,
abstract = {Many “big data” applications must act on data in real time. Running these applications at ever-larger scales re- quires parallel platforms that automatically handle faults and stragglers. Unfortunately, current distributed stream processing models provide fault recovery in an expen- sive manner, requiring hot replication or long recovery times, and do not handle stragglers. We propose a new processing model, discretized streams (D-Streams), that overcomes these challenges. D-Streams enable a par- allel recovery mechanism that improves efficiency over traditional replication and backup schemes, and tolerates stragglers.We show that they support a rich set of oper- ators while attaining high per-node throughput similar to single-node systems, linear scaling to 100 nodes, sub- second latency, and sub-second fault recovery. Finally, D-Streams can easily be composed with batch and in- teractive query models like MapReduce, enabling rich applications that combine these modes. We implement D-Streams in a system called Spark Streaming.},
author = {Zaharia, Matei and Das, Tathagata and Li, Haoyuan and Hunter, Timothy and Shenker, Scott and Stoica, Ion},
doi = {10.1145/2517349.2522737},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/spark/p423-zaharia.pdf:pdf},
isbn = {9781450323888},
journal = {Sosp},
number = {1},
pages = {423--438},
title = {{Discretized Streams: Fault-Tolerant Streaming Computation at Scale}},
url = {http://dx.doi.org/10.1145/2517349.2522737},
year = {2013}
}
@article{Daniel2014,
author = {Daniel, Jakub},
doi = {10.1145/2557833.2560573},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/p39c-daniel.pdf:pdf},
keywords = {java pathfinder,predicate abstraction,state space traversal},
number = {1},
pages = {1--5},
title = {{Predicate Abstraction in Java Pathfinder}},
volume = {39},
year = {2014}
}
@article{Meng2016,
archivePrefix = {arXiv},
arxivId = {arXiv:1505.06807v1},
author = {Meng, Xiangrui and Bradley, Joseph and Street, Spear and Francisco, San and Sparks, Evan and Berkeley, U C and Hall, Soda and Street, Spear and Francisco, San and Xin, Doris and Xin, Reynold and Franklin, Michael J and Berkeley, U C and Hall, Soda},
eprint = {arXiv:1505.06807v1},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/spark/p1235-meng.pdf:pdf},
journal = {Journal of Machine Learning Research},
pages = {1--7},
title = {{MLlib : Machine Learning in Apache Spark}},
volume = {17},
year = {2016}
}
@article{Khyzha2012,
author = {Khyzha, Artem and Par{\'{i}}zek, Pavel and Păsăreanu, Corina S.},
doi = {10.1145/2382756.2382794},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/p37-3-khyzha.pdf:pdf},
issn = {01635948},
journal = {ACM SIGSOFT Software Engineering Notes},
keywords = {abstraction,java pathfinder,state space traversal},
number = {6},
pages = {1},
title = {{Abstract pathfinder}},
url = {http://dl.acm.org/citation.cfm?doid=2382756.2382794},
volume = {37},
year = {2012}
}
@article{VanderMerwe2012,
abstract = {Mobile application testing is a specialised and complex field. Due to mobile applications' event driven design and mo- bile runtime environment, there currently exist only a small number of tools to verify these applications. This paper describes the development of JPF-ANDROID, an Android application verification tool. JPF-ANDROID is built on Java Pathfinder, a Java model checking engine. JPF-ANDROID provides a simplified model of the Android framework on which an Android application can run. It then allows the user to script input events to drive the application flow. JPF-ANDROID provides a way to detect common property violations such as deadlocks and runtime exceptions in Android applications.},
author = {van der Merwe, Heila and van der Merwe, Brink and Visser, Willem},
doi = {10.1145/2382756.2382797},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/android/p38-2-vandermerwe.pdf:pdf},
isbn = {9781457716393},
issn = {01635948},
journal = {ACM SIGSOFT Software Engineering Notes},
keywords = {JPF,Java Pathfinder,android,automatic verification,mobile application,model checking,testing},
number = {6},
pages = {1},
title = {{Verifying Android applications using Java PathFinder}},
url = {http://dl.acm.org/citation.cfm?doid=2382756.2382797},
volume = {37},
year = {2012}
}
@article{Visser2008,
abstract = {Techniques for checking complex software range from model checking and static analysis to testing. We aim to use the power of exhaustive techniques, such as model checking and symbolic execution, to enable thorough testing of complex software. In particular, we have extended the Java PathFinder model checking tool (JPF) [3] with a symbolic execution capability [4,2] to enable test case generation for Java programs. Our techniques handle complex data structures, arrays, as well as multithreading, and generate optimized test suites that satisfy user-specified testing coverage criteria.},
author = {Păsăreanu, Corina S. and Visser, Willem},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/chp{\%}3A10.1007{\%}2F978-3-540-77966-7{\_}5.pdf:pdf},
isbn = {978-3-540-77964-3, 978-3-540-77966-7},
journal = {HVC 2007},
number = {2007},
pages = {17--18},
title = {{Symbolic Execution and Model Checking for Testing}},
volume = {4424},
year = {2008}
}
@article{Visser2003,
author = {Visser, Willem and Havelund, Klaus and Brat, Guillaume and Park, Seungjoon and Lerda, Flavio},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/art{\%}3A10.1023{\%}2FA{\%}3A1022920129859.pdf:pdf},
keywords = {abstraction,java,model checking,runtime analysis,static analysis,symmetry},
pages = {203--232},
title = {{Model Checking Programs}},
year = {2003}
}
@article{Visser2004,
author = {Păsăreanu, Corina S. and Visser, Willem},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/chp{\%}3A10.1007{\%}2F978-3-540-24732-6{\_}13.pdf:pdf},
pages = {164--181},
title = {{Verification of Java Programs Using Symbolic Execution and Invariant Generation}},
year = {2004}
}
@article{Armbrust2015a,
abstract = {Apache Spark is one of the most widely used open source processing engines for big data, with rich language-integrated APIs and a wide range of libraries. Over the past two years, our group has worked to deploy Spark to a wide range of organizations through consulting relationships as well as our hosted service, Databricks. We describe the main challenges and requirements that appeared in taking Spark to a wide set of users, and usability and performance improvements we have made to the engine in response.},
author = {Armbrust, Michael and Zaharia, Matei and Das, Tathagata and Davidson, Aaron and Ghodsi, Ali and Or, Andrew and Rosen, Josh and Stoica, Ion and Wendell, Patrick and Xin, Reynold},
doi = {10.14778/2824032.2824080},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/spark/p1840-armbrust.pdf:pdf},
issn = {21508097},
journal = {Proceedings of the VLDB Endowment},
number = {12},
pages = {1840--1843},
title = {{Scaling spark in the real world: performance and usability}},
url = {http://dl.acm.org/citation.cfm?id=2824032.2824080},
volume = {8},
year = {2015}
}
@article{Person,
abstract = {Detecting and characterizing the effects of software changes is a fundamental component of software maintenance. Version differencing information can be used to perform version merging, infer change characteristics, produce program documentation, and guide program re-validation. Existing techniques for characterizing code changes, however, are imprecise leading to unnecessary maintenance efforts. In this paper, we introduce a novel extension and application of symbolic execution techniques that computes a precise behavioral characterization of a program change. This technique, which we call differential symbolic execution (DSE), exploits the fact that program versions are largely similar to reduce cost and improve the quality of analysis results. We define the foundational concepts of DSE, describe cost-effective tool support for DSE, and illustrate its potential benefit through an exploratory study that considers version histories of two Java code bases. {\textcopyright} 2008 ACM.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Person, Suzette and Dwyer, Matthew B and Elbaum, Sebastian and Păsăreanu, Corina S. and Hall, Avery},
doi = {10.1145/1453101.1453131},
eprint = {arXiv:1011.1669v3},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/jpf/symbolic/p226-person.pdf:pdf},
isbn = {9781595939951},
issn = {1098-6596},
journal = {Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
keywords = {Program Differencing,Software Evolution,Symbolic Execution},
number = {1},
pages = {226--237},
pmid = {25246403},
title = {{Differential symbolic execution}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77950482688{\&}partnerID=40{\&}md5=8395a2d6705832afcb42572a34d81444},
year = {2008}
}
@article{Zaharia2014,
abstract = {The past few years have seen a major change in computing systems, as growing data volumes and stalling processor speeds require more and more applications to scale out to distributed systems. Today, a myriad data sources, from the Internet to business operations to scientific instruments, produce large and valuable data streams. However, the processing capabilities of single machines have not kept up with the size of data, making it harder and harder to put to use. As a result, a growing number of organizations—not just web companies, but traditional enterprises and research labs—need to scale out their most important computations to clusters of hundreds of machines. At the same time, the speed and sophistication required of data processing have grown. In addition to simple queries, complex algorithms like machine learning and graph analysis are becoming common in many domains. And in addition to batch processing, streaming analysis of new real-time data sources is required to let organizations take timely action. Future computing platforms will need to not only scale out traditional workloads, but support these new applications as well. This dissertation proposes an architecture for cluster computing systems that can tackle emerging data processing workloads while coping with larger and larger scales. Whereas early cluster computing systems, like MapReduce, handled batch processing, our architecture also enables streaming and interactive queries, while keeping the scalability and fault tolerance of previous systems. And whereas most deployed systems only support simple one-pass computations (e.g., aggregation or SQL queries), ours also extends to the multi-pass algorithms required for more complex analytics (e.g., iterative algorithms for machine learning). Finally, unlike the specialized systems proposed for some of these workloads, our architecture allows these computations to be combined, enabling rich new applications that intermix, for example, streaming and batch processing, or SQL and complex analytics. We achieve these results through a simple extension to MapReduce that adds primitives for data sharing, called Resilient Distributed Datasets (RDDs). We show that this is enough to efficiently capture a wide range of workloads. We implement RDDs in the open source Spark system, which we evaluate using both synthetic benchmarks and real user applications. Spark matches or exceeds the performance of specialized systems in many application domains, while offering stronger fault tolerance guarantees and allowing these workloads to be combined. We explore the generality of RDDs from both a theoretical modeling perspective and a practical perspective to see why this extension can capture a wide range of previously disparate workloads.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Zaharia, Matei},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/spark/An Architecture for Fast and General Data Processing on Large Clusters.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
journal = {Berkeley Technical Report},
pages = {128},
pmid = {25246403},
title = {{An Architecture for Fast and General Data Processing on Large Clusters}},
year = {2014}
}
@article{Avgerinos2014,
abstract = {We present MergePoint, a new binary-only symbolic execution system for large-scale and fully unassisted testing of commodity off-the-shelf (COTS) software. MergePoint introduces veritesting, a new technique that employs static symbolic execution to amplify the effect of dynamic symbolic execution. Veritesting allows MergePoint to find twice as many bugs, explore orders of magnitude more paths, and achieve higher code coverage than previous dynamic symbolic execution systems. MergePoint is currently running daily on a 100 node cluster analyzing 33,248 Linux binaries; has generated more than 15 billion SMT queries, 200 million test cases, 2,347,420 crashes, and found 11,687 bugs in 4,379 distinct applications.},
author = {Avgerinos, Thanassis and Rebert, Alexandre and Cha, Sang Kil and Brumley, David},
doi = {10.1145/2568225.2568293},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/p1083-avgerinos.pdf:pdf},
isbn = {9781450327565},
issn = {9781450327565},
journal = {Proceedings of the 36th International Conference on Software Engineering - ICSE 2014},
keywords = {symbolic execution,verification,veritesting},
pages = {1083--1094},
title = {{Enhancing Symbolic Execution with Veritesting}},
url = {http://dl.acm.org/citation.cfm?doid=2568225.2568293},
year = {2014}
}
@article{Christakis2016,
abstract = {Most techniques to detect program errors, such as testing, code reviews, and static program analysis, do not fully verify all possible executions of a program. They leave executions unverified when they do not check an execution path, check it under certain unjustified assumptions (such as the absence of arithmetic overflow), or fail to verify certain properties. In this paper, we present a technique to complement par-tial verification results by automatic test case generation. We annotate programs to reflect which executions have been verified, and under which assumptions. These annotations are then used to guide dynamic symbolic execution toward unverified program executions. Our main contribution is a code instrumentation that causes dynamic symbolic execu-tion to abort tests that lead to verified executions, to prune parts of the search space, and to prioritize tests that lead to unverified executions. We have implemented our tech-nique for the .NET static analyzer Clousot and the dynamic symbolic execution tool Pex. Compared to directly running Pex on the annotated programs without our instrumenta-tion, our approach produces smaller test suites (by up to 19.2{\%}), covers more unverified executions (by up to 7.1{\%}), and reduces testing time (by up to 52.4{\%}).},
author = {Christakis, Maria and M{\"{u}}ller, Peter and W{\"{u}}stholz, Valentin},
doi = {10.1145/2884781.2884843},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/p144-christakis.pdf:pdf},
isbn = {9781450339001},
issn = {02705257},
journal = {Proceedings of the 38th International Conference on Software Engineering - ICSE '16},
keywords = {dynamic symbolic execution,partial verification,program verification,static analysis,testing},
pages = {144--155},
title = {{Guiding dynamic symbolic execution toward unverified program executions}},
url = {http://dl.acm.org/citation.cfm?doid=2884781.2884843},
year = {2016}
}
@article{Gulzar2016,
abstract = {Developers use cloud computing platforms to process a large quantity of data in parallel when developing big data analytics. Debugging the massive parallel computations that run in today's data-centers is time consuming and error-prone. To address this challenge, we design a set of interactive, real-time debugging primitives for big data processing in Apache Spark, the next generation data-intensive scalable cloud computing platform. This requires re-thinking the notion of step-through debugging in a traditional debugger such as gdb, because pausing the entire computation across distributed worker nodes causes significant delay and naively inspecting millions of records using a watchpoint is too time consuming for an end user. First, BIGDEBUG's simulated breakpoints and on-demand watchpoints allow users to selectively examine distributed, intermediate data on the cloud with little overhead. Second, a user can also pinpoint a crash-inducing record and selectively resume relevant sub-computations after a quick fix. Third, a user can determine the root causes of errors (or delays) at the level of individual records through a fine-grained data provenance capability. Our evaluation shows that BIGDEBUG scales to terabytes and its record-level tracing incurs less than 25{\%} overhead on average. It determines crash culprits orders of magnitude more accurately and provides up to 100{\%} time saving compared to the baseline replay debugger. The results show that BIGDEBUG supports debugging at interactive speeds with minimal performance impact.},
author = {Gulzar, Muhammad Ali and Interlandi, Matteo and Yoo, Seunghyun and Tetali, Sai Deep and Condie, Tyson and Millstein, Todd and Kim, Miryung},
doi = {10.1145/2884781.2884813},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/spark/p784-gulzar.pdf:pdf},
isbn = {9781450339001 | 9781450342056},
issn = {02705257},
journal = {Proceedings - International Conference on Software Engineering. International Conference on Software Engineering},
keywords = {Debugging, big data analytics, interactive tools,,able computing,big data analytics,data-intensive scal-,debugging,disc,fault localization and recovery,interactive tools},
pages = {784--795},
pmid = {27390389},
title = {{BigDebug: Debugging Primitives for Interactive Big Data Processing in Spark.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/27390389},
volume = {2016},
year = {2016}
}
@article{Salihoglu2015,
abstract = {We address the problem of debugging programs written for Pregel-like systems. After interviewing Giraph and GPS users, we devel-oped Graft. Graft supports the debugging cycle that users typically go through: (1) Users describe programmatically the set of vertices they are interested in inspecting. During execution, Graft captures the context information of these vertices across supersteps. (2) Us-ing Graft's GUI, users visualize how the values and messages of the captured vertices change from superstep to superstep,narrowing in suspicious vertices and supersteps. (3) Users replay the exact lines of the vertex.compute() function that executed for the sus-picious vertices and supersteps, by copying code that Graft gener-ates into their development environments' line-by-line debuggers. Graft also has features to construct end-to-end tests for Giraph pro-grams. Graft is open-source and fully integrated into Apache Gi-raph's main code base.},
author = {Salihoglu, Semih and Shin, Jaeho and Khanna, Vikesh and Truong, Ba Quan and Widom, Jennifer},
doi = {10.1145/2723372.2735353},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/p1403-salihoglu.pdf:pdf},
isbn = {978-1-4503-2758-9},
issn = {07308078},
journal = {Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data},
keywords = {debugging,distributed bulk synchronous parallel graph syste,distributed graph systems},
pages = {1403--1408},
title = {{Graft: A Debugging Tool For Apache Giraph}},
url = {http://doi.acm.org/10.1145/2723372.2735353},
year = {2015}
}
@article{Interlandi2015,
abstract = {Debugging data processing logic in Data-Intensive Scalable Computing (DISC) systems is a difficult and time consuming effort. Today's DISC systems offer very little tooling for debugging programs, and as a result programmers spend countless hours collecting evidence (e.g., from log files) and performing trial and error debugging. To aid this effort, we built Titian, a library that enables data provenance— tracking data through transformations—in Apache Spark. Data scientists using the Titian Spark extension will be able to quickly identify the input data at the root cause of a potential bug or outlier result. Titian is built directly into the Spark platform and offers data provenance support at interactive speeds—orders-of-magnitude faster than alternative solutions—while minimally impacting Spark job performance; observed overheads for capturing data lineage rarely exceed 30{\%} above the baseline job execution time.},
author = {Interlandi, Matteo and Shah, Kshitij and Tetali, Sai Deep and Gulzar, Muhammad Ali and Yoo, Seunghyun and Kim, Miryung and Millstein, Todd and Condie, Tyson},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/spark/p216-interlandi.pdf:pdf},
issn = {2150-8097},
journal = {Proceedings of the VLDB Endowment},
number = {3},
pages = {216--227},
title = {{Titian: Data Provenance Support in Spark}},
url = {http://www.vldb.org/pvldb/vol9/p216-interlandi.pdf},
volume = {9},
year = {2015}
}
@article{Dave,
abstract = {Debugging the massive parallel computations that run in today's datacenters is hard, as they consist of thousands of tasks processing terabytes of data. It is especially hard in production settings, where performance overheads of more than a few percent are unacceptable. To address this challenge, we present Arthur, a new debugger that pro-vides a rich set of analysis tools at close to zero runtime overhead through selective replay of data flow applica-tions. Unlike previous replay debuggers, which add high overheads due to the need to log low-level nondetermin-istic events, Arthur takes advantage of the structure of large-scale data flow models (e.g., MapReduce), which split work into deterministic tasks for fault tolerance, to minimize its logging cost. We use selective replay to im-plement a variety of debugging features, including re-running any task in a single-process debugger; ad-hoc queries on computation state; and forward and backward tracing of records through the computation, which we achieve using a program transformation at replay time. We implement Arthur for Hadoop and Spark, and show that it can be used to find a variety of real bugs.},
author = {Dave, Ankur and Zaharia, Matei and Shenker, Scott and Stoica, Ion},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/big data/spark/Arthur{\_}Rich{\_}Post-Facto{\_}Debugging{\_}for{\_}Pro.pdf:pdf},
title = {{Arthur: Rich Post-Facto Debugging for Production Analytics Applications}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.300.2760},
year = {2013}
}
@article{Armbrust2015,
abstract = {Spark SQL is a new module in Apache Spark that integrates relational processing with Spark's functional programming API. Built on our experience with Shark, Spark SQL lets Spark programmers leverage the benefits of relational processing (e.g. declarative queries and optimized storage), and lets SQL users call complex analytics libraries in Spark (e.g. machine learning). Compared to previous systems, Spark SQL makes two main additions. First, it offers much tighter integration between relational and procedural processing, through a declarative DataFrame API that integrates with procedural Spark code. Second, it includes a highly extensible optimizer, Catalyst, built using features of the Scala programming language, that makes it easy to add composable rules, control code generation, and define extension points. Using Catalyst, we have built a variety of features (e.g. schema inference for JSON, machine learning types, and query federation to external databases) tailored for the complex needs of modern data analysis. We see Spark SQL as an evolution of both SQL-on-Spark and of Spark itself, offering richer APIs and optimizations while keeping the benefits of the Spark programming model.},
author = {Armbrust, Michael and Ghodsi, Ali and Zaharia, Matei and Xin, Reynold S. and Lian, Cheng and Huai, Yin and Liu, Davies and Bradley, Joseph K. and Meng, Xiangrui and Kaftan, Tomer and Franklin, Michael J.},
doi = {10.1145/2723372.2742797},
file = {:home/omar/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Armbrust et al. - 2015 - Spark SQL.pdf:pdf},
isbn = {9781450327589},
issn = {07308078},
journal = {Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data - SIGMOD '15},
keywords = {data warehouse,databases,hadoop,machine learning,spark},
pages = {1383--1394},
title = {{Spark SQL}},
url = {http://dl.acm.org/citation.cfm?id=2723372.2742797},
year = {2015}
}
@article{Schutte2015,
abstract = {Recent years have seen the development of a multitude of tools for the security analysis of Android applications. A major deficit of current fully automated security analyses, however, is their inability to drive execution to interesting parts, such as where code is dynamically loaded or certain data is decrypted. In fact, security-critical or downright offensive code may not be reached at all by such analyses when dynamically checked conditions are not met by the analysis environment. To tackle this unsolved problem, we propose a tool combining static call path analysis with byte code instrumentation and a heuristic partial symbolic execution, which aims at executing interesting calls paths. It can systematically locate potentially security-critical code sections and instrument applications such that execution of these sections can be observed in a dynamic analysis. Among other use cases, this can be leveraged to force applications into revealing dynamically loaded code, a simple yet effective way to circumvent detection by security analysis software such as the Google Play Store's Bouncer. We illustrate the functionality of our tool by means of a simple logic bomb example and a real-life security vulnerability which is present in hunderd of apps and can still be actively exploited at this time.},
author = {Sch{\"{u}}tte, Julian and Fedler, Rafael and Titze, Dennis},
doi = {10.1109/AINA.2015.238},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/07098023.pdf:pdf},
isbn = {9781479979042},
issn = {1550445X},
journal = {Proceedings - International Conference on Advanced Information Networking and Applications, AINA},
keywords = {Android,Automated Analysis,Partial Symbolic Execution},
pages = {571--578},
title = {{ConDroid: Targeted dynamic analysis of android applications}},
volume = {2015-April},
year = {2015}
}
@article{Dhok2016,
abstract = {Conventional concolic testing has been used to provide high coverage of paths in statically typed languages. While it has also been applied in the context of JavaScript (JS) programs, we observe that applying concolic testing to dynamically-typed JS programs involves tackling unique problems to en-sure scalability. In particular, a naive type-agnostic exten-sion of concolic testing to JS programs causes generation of large number of inputs. Consequently, many executions op-erate on undefined values and repeatedly explore same paths resulting in redundant tests, thus diminishing the scalability of testing drastically. In this paper, we address this problem by proposing a sim-ple yet effective approach that incorporates type-awareness intelligently in conventional concolic testing to reduce the number of generated inputs for JS programs. We extend our approach inter-procedurally by generating preconditions for each function that provide a summary of the relation be-tween the variable types and paths. Employing the function preconditions when testing reduces the number of inputs generated even further. We implement our ideas and validate it on a number of open-source JS programs (and libraries). For a significant percentage (on average 50{\%}) of the functions, we observe that type-aware concolic testing generates a minuscule per-centage (less than 5{\%}) of the inputs as compared to con-ventional concolic testing approach implemented on top of Jalangi. On average, this approach achieves over 97{\%} of line coverage and over 94{\%} of branch coverage for all the functions across all benchmarks. Moreover, the use of func-tion preconditions reduces the number of inputs generated by 50{\%}. We also demonstrate the use of function precon-ditions in automatically avoiding real crashes due to incor-rectly typed objects.},
archivePrefix = {arXiv},
arxivId = {arXiv:1508.06655v1},
author = {Dhok, Monika and Ramanathan, Murali Krishna and Sinha, Nishant},
doi = {10.1145/2884781.2884859},
eprint = {arXiv:1508.06655v1},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/p168-dhok.pdf:pdf},
isbn = {9781450339001},
issn = {9781450321389},
journal = {Proceedings of the 38th International Conference on Software Engineering - ICSE '16},
keywords = {JavaScript,dynamic analysis,testing},
pages = {168--179},
title = {{Type-aware concolic testing of JavaScript programs}},
url = {http://dl.acm.org/citation.cfm?doid=2884781.2884859},
year = {2016}
}
@article{Jeon2016a,
abstract = {Symbolic execution is a powerful program analysis tech-nique, but it is difficult to apply to programs built using frameworks such as Swing and Android, because the frame-work code itself is hard to symbolically execute. The stan-dard solution is to manually create a framework model that can be symbolically executed, but developing and maintain-ing a model is difficult and error-prone. In this paper, we present Pasket, a new system that takes a first step toward automatically generating Java framework models to support symbolic execution. Pasket's focus is on creating models by instantiating design patterns. Pasket takes as input class, method, and type information from the framework API, to-gether with tutorial programs that exercise the framework. From these artifacts and Pasket's internal knowledge of de-sign patterns, Pasket synthesizes a framework model whose behavior on the tutorial programs matches that of the origi-nal framework. We evaluated Pasket by synthesizing mod-els for subsets of Swing and Android. Our results show that the models derived by Pasket are sufficient to allow us to use off-the-shelf symbolic execution tools to analyze Java programs that rely on frameworks.},
author = {Jeon, Jinseong and Qiu, Xiaokang and Fetter-Degges, Jonathan and Foster, Jeffrey S. and Solar-Lezama, Armando},
doi = {10.1145/2884781.2884856},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/p156-jeon.pdf:pdf},
isbn = {9781450339001},
issn = {02705257},
journal = {Proceedings of the 38th International Conference on Software Engineering - ICSE '16},
keywords = {framework model,program synthesis,sketch,symbolic execution},
pages = {156--167},
title = {{Synthesizing framework models for symbolic execution}},
url = {http://dl.acm.org/citation.cfm?id=2884781.2884856},
year = {2016}
}
@article{Machiry2013,
abstract = {We present a system Dynodroid for generating relevant in- puts to unmodified Android apps. Dynodroid views an app as an event-driven program that interacts with its environ- ment by means of a sequence of events through the Android framework. By instrumenting the framework once and for all, Dynodroid monitors the reaction of an app upon each event in a lightweight manner, using it to guide the gener- ation of the next event to the app. Dynodroid also allows interleaving events from machines, which are better at gen- erating a large number of simple inputs, with events from humans, who are better at providing intelligent inputs. We evaluated Dynodroid on 50 open-source Android apps, and compared it with two prevalent approaches: users man- ually exercising apps, and Monkey, a popular fuzzing tool. Dynodroid, humans, and Monkey covered 55{\%}, 60{\%}, and 53{\%}, respectively, of each app's Java source code on average. Monkey took 20X more events on average than Dynodroid. Dynodroid also found 9 bugs in 7 of the 50 apps, and 6 bugs in 5 of the top 1,000 free apps on Google Play. Categories},
author = {Machiry, Aravind and Tahiliani, Rohan and Naik, Mayur},
doi = {10.1145/2491411.2491450},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/p224-machiry.pdf:pdf},
isbn = {9781450322379},
journal = {Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering - ESEC/FSE 2013},
keywords = {Android,GUI testing,testing event-driven programs},
pages = {224},
title = {{Dynodroid: an input generation system for Android apps}},
url = {http://dl.acm.org/citation.cfm?id=2491411.2491450},
year = {2013}
}
@article{Just2014,
abstract = {A good test suite is one that detects real faults. Because the set of faults in a program is usually unknowable, this definition is not useful to practitioners who are creating test suites, nor to researchers who are creating and evaluating tools that generate test suites. In place of real faults, testing research often uses mutants, which are artificial faults -- each one a simple syntactic variation -- that are systematically seeded throughout the program under test. Mutation analysis is appealing because large numbers of mutants can be automatically-generated and used to compensate for low quantities or the absence of known real faults. Unfortunately, there is little experimental evidence to support the use of mutants as a replacement for real faults. This paper investigates whether mutants are indeed a valid substitute for real faults, i.e., whether a test suite{\&}{\#}8217;s ability to detect mutants is correlated with its ability to detect real faults that developers have fixed. Unlike prior studies, these investigations also explicitly consider the conflating effects of code coverage on the mutant detection rate. Our experiments used 357 real faults in 5 open-source applications that comprise a total of 321,000 lines of code. Furthermore, our experiments used both developer-written and automatically-generated test suites. The results show a statistically significant correlation between mutant detection and real fault detection, independently of code coverage. The results also give concrete suggestions on how to improve mutation analysis and reveal some inherent limitations.},
author = {Just, Ren{\'{e}} and Jalali, Darioush and Inozemtseva, Laura and Ernst, Michael D and Holmes, Reid and Fraser, Gordon},
doi = {10.1145/2635868.2635929},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/others/p654-just.pdf:pdf},
isbn = {9781450330565},
journal = {Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering - FSE 2014},
keywords = {code coverage,mutation analysis,real faults,test effectiveness},
pages = {654--665},
title = {{Are mutants a valid substitute for real faults in software testing?}},
url = {http://www.linozemtseva.com/research/2014/tr/mutation/mutant{\_}tr.pdf{\%}5Cnhttp://dl.acm.org/citation.cfm?doid=2635868.2635929},
year = {2014}
}
@article{Rizzi2016,
abstract = {Our community constantly pushes the state-of-the-art by introduc-ing " new " techniques. These techniques often build on top of, and are compared against, existing systems that realize previously pub-lished techniques. The underlying assumption is that existing sys-tems correctly represent the techniques they implement. This pa-per examines that assumption through a study of KLEE, a pop-ular and well-cited tool in our community. We briefly describe six improvements we made to KLEE, none of which can be con-sidered " new " techniques, that provide order-of-magnitude perfor-mance gains. Given these improvements, we then investigate how the results and conclusions of a sample of papers that cite KLEE are affected. Our findings indicate that the strong emphasis on intro-ducing " new " techniques may lead to wasted effort, missed oppor-tunities for progress, an accretion of artifact complexity, and ques-tionable research conclusions (in our study, 27{\%} of the papers that depend on KLEE can be questioned). We conclude by revisiting initiatives that may help to realign the incentives to better support the foundations on which we build.},
archivePrefix = {arXiv},
arxivId = {arXiv:1508.06655v1},
author = {Rizzi, Eric F and Elbaum, Sebastian and Dwyer, Matthew B},
doi = {10.1145/2884781.2884835},
eprint = {arXiv:1508.06655v1},
file = {:home/omar/Documents/tu{\_}darmstadt/thesis/papers/p132-rizzi.pdf:pdf},
isbn = {9781450339001},
issn = {02705257},
journal = {Proceedings of the 38th International Conference on Software Engineering - ICSE '16},
keywords = {replication,research incentives,research tools and infrastructure},
pages = {132--143},
title = {{On the techniques we create, the tools we build, and their misalignments}},
url = {http://dl.acm.org/citation.cfm?doid=2884781.2884835},
year = {2016}
}
@article{Csallner,
author = {Csallner, Christoph and Fegaras, Leonidas},
file = {:home/omar/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Csallner, Fegaras - Unknown - New Ideas Track Testing MapReduce-Style Programs Categories and Subject Descriptors.pdf:pdf},
isbn = {9781450304436},
keywords = {MapReduce,dynamic symbolic execution,test generation},
title = {{New Ideas Track : Testing MapReduce-Style Programs Categories and Subject Descriptors}}
}
@article{Ghemawat2003,
archivePrefix = {arXiv},
arxivId = {z0024},
author = {Ghemawat, Sanjay and Gobioff, Howard and Leung, Shun-tak},
doi = {10.1145/1165389.945450},
eprint = {z0024},
file = {:home/omar/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghemawat, Gobioff, Leung - 2003 - Google{\_}File{\_}System.pdf:pdf},
isbn = {1581137575},
issn = {01635980},
keywords = {clustered storage,data storage,fault tolerance,scalability},
pmid = {191},
title = {{Google{\_}File{\_}System}},
year = {2003}
}
@article{Zaharia2012a,
abstract = {We present Resilient Distributed Datasets (RDDs), a distributed memory abstraction that lets programmers perform in-memory computations on large clusters in a fault-tolerant manner. RDDs are motivated by two types of applications that current computing frameworks handle inefficiently: iterative algorithms and interactive data mining tools. In both cases, keeping data in memory can improve performance by an order of magnitude. To achieve fault tolerance efficiently, RDDs provide a restricted form of shared memory, based on coarse-grained transformations rather than fine-grained updates to shared state. However, we show that RDDs are expressive enough to capture a wide class of computations, including recent specialized programming models for iterative jobs, such as Pregel, and new applications that these models do not capture. We have implemented RDDs in a system called Spark, which we evaluate through a variety of user applications and benchmarks.},
archivePrefix = {arXiv},
arxivId = {EECS-2011-82},
author = {Zaharia, Matei and Chowdhury, Mosharaf and Das, Tathagata and Dave, Ankur},
doi = {10.1111/j.1095-8649.2005.00662.x},
eprint = {EECS-2011-82},
file = {:home/omar/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zaharia et al. - 2012 - Resilient distributed datasets A fault-tolerant abstraction for in-memory cluster computing.pdf:pdf},
isbn = {978-931971-92-8},
issn = {00221112},
journal = {NSDI'12 Proceedings of the 9th USENIX conference on Networked Systems Design and Implementation},
pages = {2--2},
pmid = {2011},
title = {{Resilient distributed datasets: A fault-tolerant abstraction for in-memory cluster computing}},
url = {https://www.usenix.org/system/files/conference/nsdi12/nsdi12-final138.pdf},
year = {2012}
}
@article{Godefroid2005,
abstract = {We present a new tool, named DART, for automatically testing software that combines three main techniques: (1) automated extraction of the interface of a program with its external environment using static source-code parsing; (2) automatic generation of a test driver for this interface that performs random testing to simulate the most general environment the program can operate in; and (3) dynamic analysis of how the program behaves under random testing and automatic generation of new test inputs to direct systematically the execution along alternative program paths. Together, these three techniques constitute Directed Automated Random Testing, or DART for short. The main strength of DART is thus that testing can be performed completely automatically on any program that compiles – there is no need to write any test driver or harness code. During testing, DART detects standard errors such as program crashes, assertion violations, and non-termination. Preliminary experiments to unit test several examples of C programs are very encouraging.},
author = {Godefroid, Patrice and Klarlund, Nils and Sen, Koushik},
doi = {10.1145/1065010.1065036},
file = {:home/omar/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Godefroid, Klarlund, Sen - 2005 - DART directed automated random testing.pdf:pdf},
isbn = {1595930809},
issn = {03621340},
journal = {Proceedings of the 2005 ACM SIGPLAN conference on Programming language design and implementation},
keywords = {automated test generation,interfaces,program verification,random testing,software testing},
pages = {213--223},
title = {{DART: directed automated random testing}},
url = {http://doi.acm.org/10.1145/1065010.1065036},
year = {2005}
}
@article{Cadar2008,
abstract = {We present a new symbolic execution tool, KLEE, capable of automatically generating tests that achieve high coverage on a diverse set of complex and environmentally-intensive programs. We used KLEE to thoroughly check all 89 stand-alone programs in the GNU COREUTILS utility suite, which form the core user-level environment installed on millions of Unix systems, and arguably are the single most heavily tested set of open-source programs in existence. KLEE-generated tests achieve high line coverage - on average over 90{\%} per tool (median: over 94{\%}) - and significantly beat the coverage of the developers' own hand-written test suite. When we did the same for 75 equivalent tools in the BUSYBOX embedded system suite, results were even better, including 100{\%} coverage on 31 of them. We also used KLEE as a bug finding tool, applying it to 452 applications (over 430K total lines of code), where it found 56 serious bugs, including three in COREUTILS that had been missed for over 15 years. Finally, we used KLEE to crosscheck purportedly identical BUSYBOX and COREUTILS utilities, finding functional correctness errors and a myriad of inconsistencies.},
author = {Cadar, Cristian and Dunbar, Daniel and Engler, Dawson R.},
doi = {10.1.1.142.9494},
file = {:home/omar/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cadar, Dunbar, Engler - 2008 - KLEE Unassisted and Automatic Generation of High-Coverage Tests for Complex Systems Programs.pdf:pdf},
isbn = {978-1-931971-65-2},
issn = {{\textless}null{\textgreater}},
journal = {Proceedings of the 8th USENIX conference on Operating systems design and implementation},
pages = {209--224},
title = {{KLEE: Unassisted and Automatic Generation of High-Coverage Tests for Complex Systems Programs}},
url = {http://portal.acm.org/citation.cfm?id=1855756},
year = {2008}
}
@article{Godefroid2008,
abstract = {Fuzz testing is an effective technique for finding security vulnerabilities in software. Traditionally, fuzz testing tools apply random mutations to well-formed inputs of a pro- gram and test the resulting values. We present an alterna- tive whitebox fuzz testing approach inspired by recent ad- vances in symbolic execution and dynamic test generation. Our approach records an actual run of the program un- der test on a well-formed input, symbolically evaluates the recorded trace, and gathers constraints on inputs capturing how the program uses these. The collected constraints are then negated one by one and solved with a constraint solver, producing new inputs that exercise different control paths in the program. This process is repeated with the help of a code-coveragemaximizing heuristic designed to find defects as fast as possible. We have implemented this algorithm in SAGE (Scalable, Automated, Guided Execution), a new tool employing x86 instruction-level tracing and emulation for whitebox fuzzing of arbitrary file-reading Windows ap- plications. We describe key optimizations needed to make dynamic test generation scale to large input files and long execution traces with hundreds of millions of instructions. We then present detailed experiments with severalWindows applications. Notably, without any format-specific knowl- edge, SAGE detects theMS07-017 ANI vulnerability, which was missed by extensive blackbox fuzzing and static analy- sis tools. Furthermore, while still in an early stage of de- velopment, SAGE has already discovered 30+ new bugs in large shipped Windows applications including image pro- cessors, media players, and file decoders. Several of these bugs are potentially exploitable memory access violations.},
author = {Godefroid, Patrice and Levin, Michael Y. and Molnar, David a.},
file = {:home/omar/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Godefroid, Levin, Molnar - 2008 - Automated Whitebox Fuzz Testing.pdf:pdf},
issn = {1064-3745},
journal = {Ndss},
number = {July},
pmid = {7581676},
title = {{Automated Whitebox Fuzz Testing}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.151.9430{\&}rep=rep1{\&}type=pdf},
year = {2008}
}
@article{Dean2004,
abstract = {MapReduce is a programming model and an associated implementation for processing and generating large data sets. Users specify a map function that processes a key/value pair to generate a set of intermediate key/value pairs, and a reduce function that merges all intermediate values associated with the same intermediate key. Many real world tasks are expressible in this model, as shown in the paper. Programs written in this functional style are automatically parallelized and executed on a large cluster of commodity machines. The run-time system takes care of the details of partitioning the input data, scheduling the program's execution across a set of machines, handling machine failures, and managing the required inter-machine communication. This allows programmers without any experience with parallel and distributed systems to easily utilize the resources of a large distributed system. Our implementation of MapReduce runs on a large cluster of commodity machines and is highly scalable: a typical MapReduce computation processes many terabytes of data on thousands of machines. Programmers find the system easy to use: hundreds of MapReduce programs have been implemented and upwards of one thousand MapReduce jobs are executed on Google's clusters every day.},
archivePrefix = {arXiv},
arxivId = {10.1.1.163.5292},
author = {Dean, Jeffrey and Ghemawat, Sanjay},
doi = {10.1145/1327452.1327492},
eprint = {10.1.1.163.5292},
file = {:home/omar/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dean, Ghemawat - 2004 - MapReduce Simplied Data Processing on Large Clusters.pdf:pdf},
isbn = {9781595936868},
issn = {00010782},
journal = {Proceedings of 6th Symposium on Operating Systems Design and Implementation},
pages = {137--149},
pmid = {11687618},
title = {{MapReduce: Simplied Data Processing on Large Clusters}},
year = {2004}
}
